{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b4451e7-1334-4435-9225-70e3a287d2e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks Collaboration & Adoption Monitor\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides a **comprehensive analysis of platform adoption and user collaboration** by tracking user activity, feature usage, AI/agent adoption, and collaboration patterns. The output includes detailed reports on active users, feature adoption rates, AI assistant usage, inactive accounts, and training needs.\n",
    "\n",
    "**✨ Enterprise-grade adoption monitoring with user activity tracking, AI/agent usage analysis, feature adoption metrics, and collaboration insights.**\n",
    "\n",
    "---\n",
    "\n",
    "## Features\n",
    "\n",
    "### User Activity Tracking\n",
    "* **Active Users**: Daily (DAU), Weekly (WAU), Monthly (MAU) active users\n",
    "* **Login Patterns**: Last login times, login frequency\n",
    "* **Inactive Users**: Users with no activity in 30/60/90 days\n",
    "* **User Segmentation**: Power users, regular users, occasional users, inactive\n",
    "* **Activity Trends**: Week-over-week, month-over-month growth\n",
    "* **Service Principal Filtering**: Excludes automated accounts from metrics\n",
    "\n",
    "### Feature Usage Analysis\n",
    "* **Feature Categorization**: Groups features into logical buckets (Notebooks, SQL, Genie/AI, Jobs, Git, MLflow, Dashboards)\n",
    "* **Category-Level Adoption**: Overall adoption rates by feature category\n",
    "* **Top Features per Category**: Most used features in each bucket\n",
    "* **Adoption Rates**: Percentage of users using each category and feature\n",
    "* **Category Ranking**: Which feature buckets are most popular\n",
    "\n",
    "### AI & Agent Adoption\n",
    "* **AI Assistant Usage**: Users leveraging Databricks Assistant\n",
    "* **AI Adoption Funnel**: Tried once → Light → Regular → Power users\n",
    "* **AI Feature Diversity**: Number of AI features explored per user\n",
    "* **AI Engagement Patterns**: Consistent vs. one-time users\n",
    "* **AI Retention**: Active vs. dormant AI users\n",
    "* **Agent Interactions**: Frequency of agent usage per user\n",
    "* **Power AI Users**: Top users by agent interaction count\n",
    "\n",
    "### User Journey Mapping\n",
    "* **Entry Points**: Where users first discover the platform (Notebooks/SQL/AI)\n",
    "* **Feature Discovery Patterns**: Natural onboarding paths\n",
    "* **Adoption Timeline**: Days to adopt key features\n",
    "* **Feature Breadth**: Single vs. multi-feature users\n",
    "* **Onboarding Success**: Users who explore multiple features\n",
    "\n",
    "### Collaboration Metrics\n",
    "* **Collaboration Score**: 0-100 score measuring team effectiveness\n",
    "* **Shared Notebooks**: Notebook editing and collaboration\n",
    "* **Dashboard Sharing**: Dashboard creation for team visibility\n",
    "* **Git Integration**: Version control usage\n",
    "* **Collaboration Recommendations**: Areas for improvement\n",
    "\n",
    "### Adoption Insights\n",
    "* **Feature Adoption Rates**: % of users using each feature\n",
    "* **Adoption Trends**: Feature usage over time\n",
    "* **Training Needs**: Users with low activity\n",
    "* **Onboarding Success**: New user activity patterns\n",
    "* **Department Analysis**: Usage by team/department\n",
    "\n",
    "### Recommendations\n",
    "* **Inactive User Cleanup**: Accounts to deactivate\n",
    "* **Training Opportunities**: Users who could benefit from training\n",
    "* **Feature Promotion**: Underutilized features to promote\n",
    "* **AI Adoption**: Users who should try AI assistant\n",
    "* **Collaboration Improvements**: Git and dashboard adoption\n",
    "\n",
    "---\n",
    "\n",
    "## Version Control\n",
    "\n",
    "| Version | Date | Author | Changes |\n",
    "|---------|------|--------|---------|  \n",
    "| 1.0.0 | 2026-02-16 | Assistant | Comprehensive collaboration and adoption monitoring system with complete user activity tracking. Features include: user inventory with activity status, login pattern analysis, active user metrics (DAU/WAU/MAU), feature usage tracking across notebooks, SQL queries, dashboards, jobs, repos, MLflow, and DLT pipelines, AI/agent usage analysis (Databricks Assistant adoption, interaction frequency, feature breakdown), inactive user identification (30/60/90 day thresholds), user segmentation (power users, regular, occasional, inactive), collaboration metrics (shared notebooks, cross-team activity, group membership), adoption rate calculations per feature, adoption trend analysis, training needs identification, recommendations for inactive user cleanup and feature promotion, multiple export formats (Delta table with historical tracking, Excel multi-sheet workbook), interactive visualizations (adoption trends, feature usage heatmap, AI adoption charts), system.access.audit log queries for activity data, job mode support with automatic configuration, serverless compute optimization, parallel processing, retry logic, progress tracking, and comprehensive error handling. |\n",
    "| 1.1.0 | 2026-02-18 | Assistant | Added service principal filtering and feature categorization. New features include: service principal filtering to exclude automated accounts from adoption metrics (filters explicit list of service accounts, UUID-pattern accounts, and group accounts starting with 'Developers-'), configurable filtering options (FILTER_SERVICE_PRINCIPALS, FILTER_UUID_ACCOUNTS, FILTER_GROUP_ACCOUNTS), before/after filtering statistics showing accounts and records removed, feature categorization into logical buckets (Notebooks, SQL, Genie/AI, Dashboards, Jobs, Git/Repos, MLflow), category-level adoption metrics with overall usage and unique user counts per category, top features displayed within each category, adoption rate calculations at both category and feature level, category adoption ranking showing most to least adopted feature areas, enhanced reporting with category summaries and feature breakdowns, improved accuracy of DAU/WAU/MAU metrics by excluding service principals, better identification of real power users vs automation, more actionable insights for training and feature promotion focused on actual human users. |\n",
    "| 1.2.0 | 2026-02-18 | Assistant | Added advanced analytics and expanded visualizations. New features include: AI Feature Breakdown with detailed adoption funnel analysis (tried once, light users 2-5, regular users 6-20, power users 20+), AI feature diversity tracking (number of AI features explored per user), AI engagement patterns (consistent vs one-time users), AI retention metrics (active vs dormant users), multi-service AI usage tracking. User Journey Mapping with entry point analysis (where users start: Notebooks/SQL/AI), feature discovery patterns, adoption timeline (days to adopt key features), feature breadth analysis (single vs multi-feature users), onboarding success metrics. Collaboration Score calculation (0-100 scale) with component breakdown (notebooks 40pts, dashboards 30pts, git 30pts), collaboration recommendations, team effectiveness assessment. Expanded visualizations from 6 to 9 charts in 3x3 grid including: AI Adoption Funnel chart showing user progression through AI adoption stages, User Journey Entry Points chart showing where users discover the platform, Collaboration Score Breakdown chart with actual vs potential scores. Enhanced insights for AI adoption strategies, onboarding optimization, and collaboration improvement initiatives. |\n",
    "\n",
    "---\n",
    "\n",
    "## Configuration\n",
    "\n",
    "### Analysis Period:\n",
    "* `LOOKBACK_DAYS = 30` - Days of activity to analyze (default: 30)\n",
    "* `INACTIVE_THRESHOLD_DAYS = 90` - Days to consider user inactive\n",
    "* `POWER_USER_THRESHOLD = 50` - Activity count to classify as power user\n",
    "\n",
    "### Service Principal Filtering:\n",
    "* `FILTER_SERVICE_PRINCIPALS = True` - Enable/disable filtering\n",
    "* `FILTER_UUID_ACCOUNTS = True` - Filter UUID-pattern accounts\n",
    "* `FILTER_GROUP_ACCOUNTS = True` - Filter 'Developers-' accounts\n",
    "* `SERVICE_PRINCIPALS = [...]` - Explicit list of service accounts to exclude\n",
    "\n",
    "### Activity Thresholds:\n",
    "* `MIN_ACTIVITY_FOR_ACTIVE = 1` - Minimum actions to count as active\n",
    "* `DAU_DAYS = 1` - Daily active users lookback\n",
    "* `WAU_DAYS = 7` - Weekly active users lookback\n",
    "* `MAU_DAYS = 30` - Monthly active users lookback\n",
    "\n",
    "### Export Settings:\n",
    "* `EXPORT_PATH = '/dbfs/tmp/adoption_export'` - Export directory\n",
    "* `ENABLE_EXCEL_EXPORT = True` - Excel workbook generation\n",
    "* `ENABLE_DELTA_EXPORT = True` - Delta table for historical tracking\n",
    "* `ENABLE_VISUALIZATIONS = True` - Generate charts (interactive mode)\n",
    "* `DELTA_TABLE_NAME = 'main.default.adoption_history'` - Delta table name\n",
    "\n",
    "### Performance Settings:\n",
    "* `MAX_USERS = 999` - Maximum users to analyze (999 = all)\n",
    "* `MAX_WORKERS = 10` - Parallel threads for API calls\n",
    "* `MAX_RETRIES = 3` - Retries for failed operations\n",
    "\n",
    "---\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Interactive Mode\n",
    "1. Run all cells to analyze adoption metrics\n",
    "2. Review user activity and feature usage by category\n",
    "3. Analyze AI adoption funnel and user journey patterns\n",
    "4. Review collaboration score and recommendations\n",
    "5. View 9 comprehensive visualizations\n",
    "6. Download Excel report from export path\n",
    "\n",
    "### Job Mode\n",
    "1. Schedule as a Databricks job (weekly recommended)\n",
    "2. Automatically runs comprehensive analysis\n",
    "3. Exports to Delta table for trend tracking\n",
    "4. Returns JSON summary for orchestration\n",
    "\n",
    "---\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "| Data Source | Purpose |\n",
    "|-------------|----------|\n",
    "| `system.access.audit` | User activity logs (notebook runs, queries, dashboard views, agent usage) |\n",
    "| Databricks SDK - Users API | User inventory, login times, active status |\n",
    "| Databricks SDK - Groups API | Group membership, collaboration patterns |\n",
    "| Workspace API | Shared notebooks, collaboration metrics |\n",
    "\n",
    "---\n",
    "\n",
    "## Key Features\n",
    "\n",
    "✓ **User Activity Tracking**: DAU/WAU/MAU metrics (real users only)  \n",
    "✓ **Service Principal Filtering**: Excludes automation from metrics  \n",
    "✓ **Feature Categorization**: Groups features into logical buckets  \n",
    "✓ **Category Adoption Metrics**: Adoption rates by feature area  \n",
    "✓ **AI Feature Breakdown**: Adoption funnel, diversity, retention  \n",
    "✓ **User Journey Mapping**: Entry points, discovery, onboarding  \n",
    "✓ **Collaboration Score**: Team effectiveness measurement (0-100)  \n",
    "✓ **9 Visualizations**: Comprehensive charts including AI funnel, journey, collaboration  \n",
    "✓ **Inactive User Detection**: 30/60/90 day inactivity thresholds  \n",
    "✓ **Power User Identification**: Top users by activity  \n",
    "✓ **Training Needs**: Identify users needing support  \n",
    "✓ **System Table Queries**: Leverages system.access.audit  \n",
    "✓ **Multiple Export Formats**: Excel and Delta table  \n",
    "✓ **Job Mode Support**: Automated scheduled execution  \n",
    "✓ **Serverless Optimized**: Compute-aware optimizations  \n",
    "✓ **Comprehensive Error Handling**: Graceful degradation  \n",
    "✓ **Historical Tracking**: Delta table with append mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee6f2225-fda1-417c-9b24-cb46b0f16a9c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install required packages"
    }
   },
   "outputs": [],
   "source": [
    "%pip install openpyxl --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c459ed3-93de-4879-945b-6d3e2a848ca5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Setup and configuration"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "# Standard library\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Third-party\n",
    "import pandas as pd\n",
    "import pytz\n",
    "\n",
    "# Databricks SDK\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.errors import NotFound, PermissionDenied\n",
    "\n",
    "# PySpark\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, TimestampType, DoubleType\n",
    "\n",
    "# ============================================================================\n",
    "# JOB MODE DETECTION (MUST BE FIRST)\n",
    "# ============================================================================\n",
    "\n",
    "try:\n",
    "    dbutils.notebook.entry_point.getDbutils().notebook().getContext().currentRunId().isDefined()\n",
    "    is_job_mode = True\n",
    "except:\n",
    "    is_job_mode = False\n",
    "\n",
    "# ============================================================================\n",
    "# SERVERLESS DETECTION\n",
    "# ============================================================================\n",
    "\n",
    "try:\n",
    "    test_df = spark.range(1)\n",
    "    test_df.cache()\n",
    "    test_df.count()\n",
    "    test_df.unpersist()\n",
    "    is_serverless = False\n",
    "except Exception as e:\n",
    "    if 'PERSIST' in str(e).upper() or 'CACHE' in str(e).upper():\n",
    "        is_serverless = True\n",
    "    else:\n",
    "        is_serverless = False\n",
    "\n",
    "# ============================================================================\n",
    "# TIMEZONE CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "TIMEZONE = 'America/New_York'\n",
    "eastern = pytz.timezone(TIMEZONE)\n",
    "\n",
    "# ============================================================================\n",
    "# LOGGING FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def log(message):\n",
    "    \"\"\"Print messages (always in interactive, selectively in job mode)\"\"\"\n",
    "    print(message)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# Analysis period\n",
    "LOOKBACK_DAYS = 30  # Days of activity to analyze\n",
    "\n",
    "# Activity thresholds\n",
    "INACTIVE_THRESHOLD_DAYS = 90  # Days to consider user inactive\n",
    "POWER_USER_THRESHOLD = 50  # Activity count to classify as power user\n",
    "MIN_ACTIVITY_FOR_ACTIVE = 1  # Minimum actions to count as active\n",
    "\n",
    "# Active user metrics\n",
    "DAU_DAYS = 1  # Daily active users\n",
    "WAU_DAYS = 7  # Weekly active users\n",
    "MAU_DAYS = 30  # Monthly active users\n",
    "\n",
    "# User limits\n",
    "MAX_USERS = 999  # Maximum users to analyze (999 = all)\n",
    "\n",
    "# Service principals to exclude from adoption analysis\n",
    "# These are automated accounts that skew adoption metrics\n",
    "SERVICE_PRINCIPALS = [\n",
    "    'System-User',\n",
    "    'System user',\n",
    "    'unknown',\n",
    "    ''   # Empty string for null emails\n",
    "]\n",
    "\n",
    "# Filter service principals by pattern\n",
    "FILTER_SERVICE_PRINCIPALS = True  # Set to False to include all accounts\n",
    "FILTER_UUID_ACCOUNTS = True       # Filter accounts that look like UUIDs\n",
    "FILTER_GROUP_ACCOUNTS = True      # Filter accounts starting with 'Developers-'\n",
    "\n",
    "# Performance settings\n",
    "MAX_WORKERS = 10\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY = 2\n",
    "\n",
    "# Export settings (disabled in interactive mode, enabled in job mode)\n",
    "EXPORT_PATH = '/dbfs/tmp/adoption_export'\n",
    "if is_job_mode:\n",
    "    ENABLE_EXCEL_EXPORT = True\n",
    "    ENABLE_DELTA_EXPORT = True\n",
    "    ENABLE_JSON_EXPORT = True\n",
    "    log(\"\uD83E\uDD16 Job mode: Exports ENABLED\")\n",
    "else:\n",
    "    ENABLE_EXCEL_EXPORT = False\n",
    "    ENABLE_DELTA_EXPORT = False\n",
    "    ENABLE_JSON_EXPORT = False\n",
    "    log(\"\uD83D\uDCBB Interactive mode: Exports DISABLED\")\n",
    "\n",
    "ENABLE_VISUALIZATIONS = True\n",
    "\n",
    "# Delta table configuration\n",
    "DELTA_TABLE_NAME = 'main.default.adoption_history'\n",
    "\n",
    "# ============================================================================\n",
    "# EXECUTION STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "execution_stats = {\n",
    "    'start_time': time.time(),\n",
    "    'api_calls': 0,\n",
    "    'api_failures': 0,\n",
    "    'users_processed': 0,\n",
    "    'audit_records_processed': 0\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# INITIALIZE SDK CLIENT\n",
    "# ============================================================================\n",
    "\n",
    "wc = WorkspaceClient()\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"COLLABORATION & ADOPTION MONITOR\")\n",
    "log(\"=\"*60)\n",
    "log(f\"Execution mode: {'JOB' if is_job_mode else 'INTERACTIVE'}\")\n",
    "log(f\"Compute type: {'SERVERLESS' if is_serverless else 'TRADITIONAL'}\")\n",
    "log(f\"Timezone: {TIMEZONE}\")\n",
    "log(f\"Lookback period: {LOOKBACK_DAYS} days\")\n",
    "log(f\"Inactive threshold: {INACTIVE_THRESHOLD_DAYS} days\")\n",
    "log(f\"Service principal filtering: {'ENABLED' if FILTER_SERVICE_PRINCIPALS else 'DISABLED'}\")\n",
    "log(f\"Excel export: {'ENABLED' if ENABLE_EXCEL_EXPORT else 'DISABLED'}\")\n",
    "log(f\"Delta export: {'ENABLED' if ENABLE_DELTA_EXPORT else 'DISABLED'}\")\n",
    "log(f\"JSON export: {'ENABLED' if ENABLE_JSON_EXPORT else 'DISABLED'}\")\n",
    "log(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4906eab8-77d7-43be-a3c3-bb40eaa6149e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Helper functions"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def log_execution_time(cell_name, start_time):\n",
    "    \"\"\"Log execution time for a cell\"\"\"\n",
    "    elapsed = time.time() - start_time\n",
    "    log(f\"⏱️  {cell_name} completed in {elapsed:.2f} seconds\")\n",
    "\n",
    "def validate_dataframe_exists(df_name, df):\n",
    "    \"\"\"Validate that a DataFrame exists and has data\"\"\"\n",
    "    if df is None:\n",
    "        log(f\"⚠️  Warning: {df_name} is None\")\n",
    "        return False\n",
    "    try:\n",
    "        count = df.count()\n",
    "        if count == 0:\n",
    "            log(f\"⚠️  Warning: {df_name} is empty (0 rows)\")\n",
    "            return False\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        log(f\"❌ Error validating {df_name}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def is_service_principal(user_name):\n",
    "    \"\"\"Determine if a user is a service principal\"\"\"\n",
    "    if not user_name or pd.isna(user_name):\n",
    "        return True  # Treat null/empty as service principal\n",
    "    \n",
    "    user_str = str(user_name).strip()\n",
    "    \n",
    "    # Check explicit list\n",
    "    if user_str in SERVICE_PRINCIPALS:\n",
    "        return True\n",
    "    \n",
    "    # Check UUID pattern (8-4-4-4-12 hex digits)\n",
    "    if FILTER_UUID_ACCOUNTS:\n",
    "        import re\n",
    "        uuid_pattern = r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$'\n",
    "        if re.match(uuid_pattern, user_str.lower()):\n",
    "            return True\n",
    "    \n",
    "    # Check group accounts\n",
    "    if FILTER_GROUP_ACCOUNTS:\n",
    "        if user_str.startswith('Developers-') or user_str.startswith('developers-'):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def filter_service_principals_spark(df, user_column='user_name'):\n",
    "    \"\"\"Filter out service principals from a Spark DataFrame\"\"\"\n",
    "    if not FILTER_SERVICE_PRINCIPALS:\n",
    "        return df\n",
    "    \n",
    "    # Filter explicit list\n",
    "    df_filtered = df.filter(~F.col(user_column).isin(SERVICE_PRINCIPALS))\n",
    "    \n",
    "    # Filter UUIDs\n",
    "    if FILTER_UUID_ACCOUNTS:\n",
    "        df_filtered = df_filtered.filter(\n",
    "            ~F.col(user_column).rlike('^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$')\n",
    "        )\n",
    "    \n",
    "    # Filter group accounts\n",
    "    if FILTER_GROUP_ACCOUNTS:\n",
    "        df_filtered = df_filtered.filter(\n",
    "            ~F.lower(F.col(user_column)).startswith('developers-')\n",
    "        )\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "def retry_with_backoff(func, *args, **kwargs):\n",
    "    \"\"\"Retry a function with exponential backoff\"\"\"\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            if attempt == MAX_RETRIES - 1:\n",
    "                raise\n",
    "            wait_time = RETRY_DELAY * (2 ** attempt)\n",
    "            log(f\"⚠️  Attempt {attempt + 1} failed: {str(e)}. Retrying in {wait_time}s...\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "log(\"✓ Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e00d5b9-fc8e-45ae-ac91-7dc26cebcad4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fetch all users and groups"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"FETCHING USERS AND GROUPS\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Fetch all users\n",
    "    log(\"Fetching users...\")\n",
    "    users = list(wc.users.list())\n",
    "    \n",
    "    if MAX_USERS < 999:\n",
    "        users = users[:MAX_USERS]\n",
    "    \n",
    "    users_data = []\n",
    "    for user in users:\n",
    "        users_data.append({\n",
    "            'user_name': user.user_name,\n",
    "            'display_name': user.display_name,\n",
    "            'active': user.active,\n",
    "            'user_id': user.id\n",
    "        })\n",
    "    \n",
    "    users_df = spark.createDataFrame(users_data)\n",
    "    \n",
    "    log(f\"✓ Fetched {len(users_data)} users\")\n",
    "    log(f\"  Active: {users_df.filter(F.col('active') == True).count()}\")\n",
    "    log(f\"  Inactive: {users_df.filter(F.col('active') == False).count()}\")\n",
    "    \n",
    "    # Fetch groups\n",
    "    log(\"Fetching groups...\")\n",
    "    groups = list(wc.groups.list())\n",
    "    \n",
    "    log(f\"✓ Fetched {len(groups)} groups\")\n",
    "    \n",
    "    execution_stats['users_processed'] = len(users_data)\n",
    "    \n",
    "except Exception as e:\n",
    "    log(f\"✗ Error fetching users: {str(e)}\")\n",
    "    users_df = None\n",
    "\n",
    "log_execution_time(\"Fetch Users\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "926d2da5-5fb2-409d-8d0b-376d6696ea68",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Query system.access.audit for user activity"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(f\"QUERYING USER ACTIVITY (LAST {LOOKBACK_DAYS} DAYS)\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "if users_df is not None:\n",
    "    try:\n",
    "        # Calculate date range\n",
    "        start_date = (datetime.now(eastern) - timedelta(days=LOOKBACK_DAYS)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        log(f\"Querying system.access.audit since {start_date}...\")\n",
    "        \n",
    "        # Query audit logs for various activities\n",
    "        activity_query = f\"\"\"\n",
    "        SELECT \n",
    "            user_identity.email as user_name,\n",
    "            action_name,\n",
    "            service_name,\n",
    "            DATE(event_date) as activity_date,\n",
    "            COUNT(*) as activity_count\n",
    "        FROM system.access.audit\n",
    "        WHERE event_date >= '{start_date}'\n",
    "            AND user_identity.email IS NOT NULL\n",
    "            AND (\n",
    "                action_name IN (\n",
    "                    'runCommand',  -- Notebook execution\n",
    "                    'submitCommand',  -- Notebook command submission\n",
    "                    'modifyNotebook',  -- Notebook editing\n",
    "                    'createNotebook',\n",
    "                    'executeQuery',  -- SQL query execution\n",
    "                    'createQuery',\n",
    "                    'createDashboard',\n",
    "                    'createJob',\n",
    "                    'runJob',\n",
    "                    'gitSync',  -- Repo activity\n",
    "                    'mlflowRunCreated'  -- MLflow usage\n",
    "                )\n",
    "                OR service_name IN (\n",
    "                    'agents',  -- AI/BI Genie agents\n",
    "                    'knowledge_assistant',  -- Knowledge assistant\n",
    "                    'supervisor_agent',  -- Supervisor agent\n",
    "                    'agentFramework',  -- Agent framework\n",
    "                    'agentEvaluation',  -- Agent evaluation\n",
    "                    'aibiGenie'  -- AI/BI Genie\n",
    "                )\n",
    "            )\n",
    "        GROUP BY user_identity.email, action_name, service_name, DATE(event_date)\n",
    "        ORDER BY activity_date DESC, user_name\n",
    "        \"\"\"\n",
    "        \n",
    "        activity_df_raw = spark.sql(activity_query)\n",
    "        \n",
    "        # Get counts before filtering\n",
    "        total_records = activity_df_raw.count()\n",
    "        total_users = activity_df_raw.select('user_name').distinct().count()\n",
    "        \n",
    "        log(f\"✓ Fetched {total_records:,} activity records from {total_users} accounts\")\n",
    "        \n",
    "        # Filter out service principals\n",
    "        if FILTER_SERVICE_PRINCIPALS:\n",
    "            log(\"Filtering out service principals...\")\n",
    "            activity_df = filter_service_principals_spark(activity_df_raw, 'user_name')\n",
    "            \n",
    "            # Get counts after filtering\n",
    "            filtered_records = activity_df.count()\n",
    "            filtered_users = activity_df.select('user_name').distinct().count()\n",
    "            \n",
    "            records_removed = total_records - filtered_records\n",
    "            users_removed = total_users - filtered_users\n",
    "            \n",
    "            log(f\"✓ After filtering:\")\n",
    "            log(f\"  Activity records: {filtered_records:,} (removed {records_removed:,}, {records_removed/total_records*100:.1f}%)\")\n",
    "            log(f\"  Unique users: {filtered_users} (removed {users_removed} service principals)\")\n",
    "        else:\n",
    "            activity_df = activity_df_raw\n",
    "            log(\"ℹ️  Service principal filtering disabled\")\n",
    "        \n",
    "        execution_stats['audit_records_processed'] = activity_df.count()\n",
    "        \n",
    "    except Exception as e:\n",
    "        log(f\"✗ Error querying audit logs: {str(e)}\")\n",
    "        log(\"  Note: Requires system.access.audit access\")\n",
    "        activity_df = None\n",
    "else:\n",
    "    log(\"⚠️  Skipping activity query (no users)\")\n",
    "    activity_df = None\n",
    "\n",
    "log_execution_time(\"Query Activity\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcadb1cc-71b4-492f-bb54-dd2038cc3b52",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Identify AI/Agent users"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"ANALYZING AI/AGENT USAGE\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "if activity_df is not None:\n",
    "    try:\n",
    "        # Filter for AI/Agent related activities by service name\n",
    "        agent_activities = activity_df.filter(\n",
    "            F.col('service_name').isin([\n",
    "                'agents',\n",
    "                'knowledge_assistant',\n",
    "                'supervisor_agent',\n",
    "                'agentFramework',\n",
    "                'agentEvaluation',\n",
    "                'aibiGenie'\n",
    "            ])\n",
    "        )\n",
    "        \n",
    "        if agent_activities.count() > 0:\n",
    "            # Calculate agent usage per user\n",
    "            agent_usage = agent_activities.groupBy('user_name').agg(\n",
    "                F.sum('activity_count').alias('agent_interactions'),\n",
    "                F.countDistinct('activity_date').alias('days_used_agent'),\n",
    "                F.max('activity_date').alias('last_agent_use'),\n",
    "                F.countDistinct('action_name').alias('unique_agent_actions')\n",
    "            )\n",
    "            \n",
    "            # Calculate agent adoption metrics\n",
    "            total_users = users_df.filter(F.col('active') == True).count()\n",
    "            agent_users_count = agent_usage.count()\n",
    "            agent_adoption_rate = (agent_users_count / total_users * 100) if total_users > 0 else 0\n",
    "            \n",
    "            total_interactions = agent_activities.agg(F.sum('activity_count')).first()[0]\n",
    "            \n",
    "            log(f\"✓ AI/Agent Usage Analysis:\")\n",
    "            log(f\"  Users using agents: {agent_users_count} ({agent_adoption_rate:.1f}% of active users)\")\n",
    "            log(f\"  Total agent interactions: {total_interactions:,}\")\n",
    "            log(f\"  Average interactions per user: {total_interactions / agent_users_count:.1f}\")\n",
    "            \n",
    "            # Top agent users\n",
    "            log(f\"\\n  Top 5 AI/Agent power users:\")\n",
    "            top_agent_users = agent_usage.orderBy(F.desc('agent_interactions')).limit(5)\n",
    "            for row in top_agent_users.collect():\n",
    "                log(f\"    - {row.user_name}: {row.agent_interactions:,} interactions over {row.days_used_agent} days\")\n",
    "            \n",
    "            # Agent service breakdown\n",
    "            log(f\"\\n  Agent service usage:\")\n",
    "            service_breakdown = agent_activities.groupBy('service_name').agg(\n",
    "                F.sum('activity_count').alias('total_count')\n",
    "            ).orderBy(F.desc('total_count'))\n",
    "            for row in service_breakdown.collect():\n",
    "                log(f\"    - {row.service_name}: {row.total_count:,} interactions\")\n",
    "            \n",
    "            # Agent action breakdown\n",
    "            log(f\"\\n  Top agent actions:\")\n",
    "            action_breakdown = agent_activities.groupBy('action_name').agg(\n",
    "                F.sum('activity_count').alias('total_count')\n",
    "            ).orderBy(F.desc('total_count')).limit(10)\n",
    "            for row in action_breakdown.collect():\n",
    "                log(f\"    - {row.action_name}: {row.total_count:,} uses\")\n",
    "            \n",
    "        else:\n",
    "            log(\"ℹ️  No AI/Agent usage detected in audit logs\")\n",
    "            log(\"  Note: Agent usage tracked via service_name (agents, knowledge_assistant, etc.)\")\n",
    "            agent_usage = None\n",
    "            agent_adoption_rate = 0\n",
    "            \n",
    "    except Exception as e:\n",
    "        log(f\"✗ Error analyzing agent usage: {str(e)}\")\n",
    "        agent_usage = None\n",
    "        agent_adoption_rate = 0\n",
    "else:\n",
    "    log(\"⚠️  Skipping agent analysis (no activity data)\")\n",
    "    agent_usage = None\n",
    "    agent_adoption_rate = 0\n",
    "\n",
    "log_execution_time(\"Agent Analysis\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b090adfe-e1b6-4f95-8967-e1c9344ceac1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "AI Feature Breakdown (Detailed)"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"AI FEATURE BREAKDOWN (DETAILED)\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "if 'agent_activities' in dir() and agent_activities is not None and agent_activities.count() > 0:\n",
    "    try:\n",
    "        # Detailed AI feature analysis\n",
    "        log(\"Analyzing AI feature usage patterns...\")\n",
    "        \n",
    "        # 1. AI Feature Adoption Funnel\n",
    "        log(\"\\n\uD83D\uDCCA AI ADOPTION FUNNEL:\")\n",
    "        \n",
    "        # Users who tried AI once\n",
    "        tried_once = agent_usage.filter(F.col('agent_interactions') == 1).count()\n",
    "        # Users who used AI 2-5 times\n",
    "        light_users = agent_usage.filter((F.col('agent_interactions') >= 2) & (F.col('agent_interactions') <= 5)).count()\n",
    "        # Users who used AI 6-20 times\n",
    "        regular_users = agent_usage.filter((F.col('agent_interactions') >= 6) & (F.col('agent_interactions') <= 20)).count()\n",
    "        # Users who used AI 20+ times (power users)\n",
    "        power_users = agent_usage.filter(F.col('agent_interactions') > 20).count()\n",
    "        \n",
    "        total_ai_users = agent_usage.count()\n",
    "        \n",
    "        log(f\"  Tried once: {tried_once} ({tried_once/total_ai_users*100:.1f}%)\")\n",
    "        log(f\"  Light users (2-5 uses): {light_users} ({light_users/total_ai_users*100:.1f}%)\")\n",
    "        log(f\"  Regular users (6-20 uses): {regular_users} ({regular_users/total_ai_users*100:.1f}%)\")\n",
    "        log(f\"  Power users (20+ uses): {power_users} ({power_users/total_ai_users*100:.1f}%)\")\n",
    "        \n",
    "        # 2. AI Feature Diversity\n",
    "        log(\"\\n\uD83C\uDFAF AI FEATURE DIVERSITY:\")\n",
    "        \n",
    "        # Users by number of different AI features used\n",
    "        feature_diversity = agent_usage.groupBy('unique_agent_actions').count().orderBy('unique_agent_actions')\n",
    "        \n",
    "        log(\"  Users by AI features explored:\")\n",
    "        for row in feature_diversity.collect():\n",
    "            log(f\"    {row['unique_agent_actions']} features: {row['count']} users\")\n",
    "        \n",
    "        # 3. AI Engagement Patterns\n",
    "        log(\"\\n\uD83D\uDCC5 AI ENGAGEMENT PATTERNS:\")\n",
    "        \n",
    "        # Average days between AI usage\n",
    "        avg_days_used = agent_usage.agg(F.avg('days_used_agent')).first()[0]\n",
    "        log(f\"  Average days with AI activity: {avg_days_used:.1f}\")\n",
    "        \n",
    "        # Users with consistent AI usage (used on 5+ different days)\n",
    "        consistent_users = agent_usage.filter(F.col('days_used_agent') >= 5).count()\n",
    "        log(f\"  Consistent AI users (5+ days): {consistent_users} ({consistent_users/total_ai_users*100:.1f}%)\")\n",
    "        \n",
    "        # 4. AI Feature Combinations\n",
    "        log(\"\\n\uD83D\uDD17 POPULAR AI FEATURE COMBINATIONS:\")\n",
    "        \n",
    "        # Users using multiple AI services\n",
    "        user_service_combos = agent_activities.groupBy('user_name').agg(\n",
    "            F.collect_set('service_name').alias('services_used')\n",
    "        )\n",
    "        \n",
    "        multi_service_users = user_service_combos.filter(F.size('services_used') > 1).count()\n",
    "        log(f\"  Users using multiple AI services: {multi_service_users} ({multi_service_users/total_ai_users*100:.1f}%)\")\n",
    "        \n",
    "        # 5. AI Retention\n",
    "        log(\"\\n\uD83D\uDCCC AI USER RETENTION:\")\n",
    "        \n",
    "        # Users who used AI in last 7 days\n",
    "        recent_cutoff = (datetime.now(eastern) - timedelta(days=7)).date()\n",
    "        recent_ai_users = agent_usage.filter(F.col('last_agent_use') >= F.lit(recent_cutoff)).count()\n",
    "        log(f\"  Active in last 7 days: {recent_ai_users} ({recent_ai_users/total_ai_users*100:.1f}%)\")\n",
    "        \n",
    "        # Users who haven't used AI in 14+ days\n",
    "        dormant_cutoff = (datetime.now(eastern) - timedelta(days=14)).date()\n",
    "        dormant_ai_users = agent_usage.filter(F.col('last_agent_use') < F.lit(dormant_cutoff)).count()\n",
    "        log(f\"  Dormant (14+ days): {dormant_ai_users} ({dormant_ai_users/total_ai_users*100:.1f}%)\")\n",
    "        \n",
    "        # Create AI metrics summary\n",
    "        ai_metrics_summary = {\n",
    "            'total_ai_users': total_ai_users,\n",
    "            'power_users': power_users,\n",
    "            'consistent_users': consistent_users,\n",
    "            'recent_active': recent_ai_users,\n",
    "            'adoption_rate': agent_adoption_rate\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        log(f\"❌ Error in AI feature breakdown: {str(e)}\")\n",
    "        ai_metrics_summary = None\n",
    "else:\n",
    "    log(\"ℹ️  No AI usage data available for detailed analysis\")\n",
    "    ai_metrics_summary = None\n",
    "\n",
    "log_execution_time(\"AI Feature Breakdown\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5b2b940-af8e-4281-9325-106b8efc60c5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "User Journey Mapping"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"USER JOURNEY MAPPING\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "if activity_df is not None:\n",
    "    try:\n",
    "        log(\"Analyzing user journey patterns...\")\n",
    "        \n",
    "        # 1. First Action Analysis\n",
    "        log(\"\\n\uD83C\uDFAF ENTRY POINTS (First Actions):\")\n",
    "        \n",
    "        # Get first action for each user\n",
    "        user_first_action = activity_df.groupBy('user_name').agg(\n",
    "            F.min('activity_date').alias('first_activity_date')\n",
    "        )\n",
    "        \n",
    "        # Join to get the action on first day - use aliases to avoid ambiguity\n",
    "        activity_aliased = activity_df.alias('act')\n",
    "        first_action_aliased = user_first_action.alias('first')\n",
    "        \n",
    "        first_actions = activity_aliased.join(\n",
    "            first_action_aliased,\n",
    "            (F.col('act.user_name') == F.col('first.user_name')) & \n",
    "            (F.col('act.activity_date') == F.col('first.first_activity_date')),\n",
    "            'inner'\n",
    "        ).select(\n",
    "            F.col('act.user_name'),\n",
    "            F.col('act.action_name').alias('first_action'),\n",
    "            F.col('act.service_name').alias('first_service')\n",
    "        ).distinct()\n",
    "        \n",
    "        # Count first actions\n",
    "        first_action_counts = first_actions.groupBy('first_action').count().orderBy(F.desc('count'))\n",
    "        \n",
    "        log(\"  Most common first actions:\")\n",
    "        for row in first_action_counts.limit(10).collect():\n",
    "            log(f\"    {row['first_action']}: {row['count']} users\")\n",
    "        \n",
    "        # 2. Feature Discovery Sequence\n",
    "        log(\"\\n\uD83D\uDD0D FEATURE DISCOVERY PATTERNS:\")\n",
    "        \n",
    "        # Users who started with notebooks\n",
    "        notebook_starters = first_actions.filter(\n",
    "            F.col('first_action').isin(['runCommand', 'modifyNotebook', 'createNotebook'])\n",
    "        ).count()\n",
    "        \n",
    "        # Users who started with SQL\n",
    "        sql_starters = first_actions.filter(\n",
    "            F.col('first_action').isin(['executeQuery', 'createQuery'])\n",
    "        ).count()\n",
    "        \n",
    "        # Users who started with AI\n",
    "        ai_starters = first_actions.filter(\n",
    "            F.col('first_service').isin(['agents', 'aibiGenie', 'knowledge_assistant'])\n",
    "        ).count()\n",
    "        \n",
    "        total_users_with_activity = first_actions.count()\n",
    "        \n",
    "        log(f\"  Started with Notebooks: {notebook_starters} ({notebook_starters/total_users_with_activity*100:.1f}%)\")\n",
    "        log(f\"  Started with SQL: {sql_starters} ({sql_starters/total_users_with_activity*100:.1f}%)\")\n",
    "        log(f\"  Started with AI: {ai_starters} ({ai_starters/total_users_with_activity*100:.1f}%)\")\n",
    "        \n",
    "        # 3. Feature Adoption Timeline\n",
    "        log(\"\\n\uD83D\uDCC5 FEATURE ADOPTION TIMELINE:\")\n",
    "        \n",
    "        # Calculate days to adopt different features\n",
    "        user_feature_timeline = activity_df.groupBy('user_name', 'action_name').agg(\n",
    "            F.min('activity_date').alias('first_use_date')\n",
    "        )\n",
    "        \n",
    "        # Join with user's first activity to calculate days to adoption\n",
    "        feature_adoption_timeline = user_feature_timeline.join(\n",
    "            user_first_action,\n",
    "            'user_name'\n",
    "        ).withColumn(\n",
    "            'days_to_adoption',\n",
    "            F.datediff(F.col('first_use_date'), F.col('first_activity_date'))\n",
    "        )\n",
    "        \n",
    "        # Average days to adopt key features\n",
    "        key_features = ['createNotebook', 'executeQuery', 'createDashboard']\n",
    "        \n",
    "        log(\"  Average days to adopt key features:\")\n",
    "        for feature in key_features:\n",
    "            avg_days = feature_adoption_timeline.filter(\n",
    "                (F.col('action_name') == feature) & (F.col('days_to_adoption') > 0)\n",
    "            ).agg(F.avg('days_to_adoption')).first()[0]\n",
    "            \n",
    "            if avg_days:\n",
    "                log(f\"    {feature}: {avg_days:.1f} days\")\n",
    "        \n",
    "        # 4. Multi-Feature Users\n",
    "        log(\"\\n\uD83C\uDF10 FEATURE BREADTH:\")\n",
    "        \n",
    "        # Users by number of unique features used\n",
    "        user_feature_breadth = activity_df.groupBy('user_name').agg(\n",
    "            F.countDistinct('action_name').alias('unique_features')\n",
    "        )\n",
    "        \n",
    "        # Categorize users by feature breadth\n",
    "        single_feature = user_feature_breadth.filter(F.col('unique_features') == 1).count()\n",
    "        few_features = user_feature_breadth.filter((F.col('unique_features') >= 2) & (F.col('unique_features') <= 5)).count()\n",
    "        many_features = user_feature_breadth.filter(F.col('unique_features') > 5).count()\n",
    "        \n",
    "        log(f\"  Single feature users: {single_feature}\")\n",
    "        log(f\"  Few features (2-5): {few_features}\")\n",
    "        log(f\"  Many features (6+): {many_features}\")\n",
    "        \n",
    "        # 5. Onboarding Success\n",
    "        log(\"\\n\uD83C\uDF93 ONBOARDING SUCCESS:\")\n",
    "        \n",
    "        # Users who became active within 7 days of first action\n",
    "        quick_adopters = user_feature_breadth.filter(F.col('unique_features') >= 3)\n",
    "        quick_adopter_count = quick_adopters.count()\n",
    "        \n",
    "        log(f\"  Users who explored 3+ features: {quick_adopter_count} ({quick_adopter_count/total_users_with_activity*100:.1f}%)\")\n",
    "        \n",
    "        # Store journey metrics\n",
    "        journey_metrics = {\n",
    "            'notebook_starters': notebook_starters,\n",
    "            'sql_starters': sql_starters,\n",
    "            'ai_starters': ai_starters,\n",
    "            'multi_feature_users': many_features\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        log(f\"❌ Error in user journey mapping: {str(e)}\")\n",
    "        import traceback\n",
    "        log(traceback.format_exc())\n",
    "        journey_metrics = None\n",
    "else:\n",
    "    log(\"ℹ️  No activity data available for journey mapping\")\n",
    "    journey_metrics = None\n",
    "\n",
    "log_execution_time(\"User Journey Mapping\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4812c0d-0349-4d09-b73a-8dc145908c22",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Collaboration Score"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"COLLABORATION SCORE ANALYSIS\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "if activity_df is not None and users_df is not None:\n",
    "    try:\n",
    "        log(\"Calculating collaboration metrics...\")\n",
    "        \n",
    "        # 1. Shared Workspace Activity\n",
    "        log(\"\\n\uD83E\uDD1D SHARED WORKSPACE ACTIVITY:\")\n",
    "        \n",
    "        # Count users working on shared notebooks (modifyNotebook action)\n",
    "        shared_notebook_users = activity_df.filter(\n",
    "            F.col('action_name') == 'modifyNotebook'\n",
    "        ).select('user_name').distinct().count()\n",
    "        \n",
    "        total_active = users_df.filter(F.col('active') == True).count()\n",
    "        \n",
    "        log(f\"  Users editing notebooks: {shared_notebook_users} ({shared_notebook_users/total_active*100:.1f}%)\")\n",
    "        \n",
    "        # 2. Group Membership Analysis\n",
    "        log(\"\\n\uD83D\uDC65 GROUP COLLABORATION:\")\n",
    "        \n",
    "        if 'groups_df' in dir() and groups_df is not None:\n",
    "            # Average groups per user\n",
    "            total_groups = groups_df.count()\n",
    "            total_users = users_df.count()\n",
    "            \n",
    "            log(f\"  Total groups: {total_groups}\")\n",
    "            log(f\"  Average groups per user: {total_groups/total_users:.1f}\")\n",
    "            \n",
    "            # Users in multiple groups (proxy for cross-team collaboration)\n",
    "            # Note: This would require group membership data from SDK\n",
    "            log(\"  ℹ️  Detailed group membership requires additional API calls\")\n",
    "        else:\n",
    "            log(\"  ℹ️  Group data not available\")\n",
    "        \n",
    "        # 3. Collaborative Features Usage\n",
    "        log(\"\\n\uD83D\uDCDD COLLABORATIVE FEATURES:\")\n",
    "        \n",
    "        # Dashboard creation (often shared)\n",
    "        dashboard_creators = activity_df.filter(\n",
    "            F.col('action_name') == 'createDashboard'\n",
    "        ).select('user_name').distinct().count()\n",
    "        \n",
    "        log(f\"  Dashboard creators: {dashboard_creators} ({dashboard_creators/total_active*100:.1f}%)\")\n",
    "        \n",
    "        # Git sync (repo collaboration)\n",
    "        git_users = activity_df.filter(\n",
    "            F.col('action_name') == 'gitSync'\n",
    "        ).select('user_name').distinct().count()\n",
    "        \n",
    "        if git_users > 0:\n",
    "            log(f\"  Git/Repo users: {git_users} ({git_users/total_active*100:.1f}%)\")\n",
    "        else:\n",
    "            log(f\"  Git/Repo users: 0 (no Git activity detected)\")\n",
    "        \n",
    "        # 4. Calculate Collaboration Score\n",
    "        log(\"\\n\uD83C\uDFC6 COLLABORATION SCORE:\")\n",
    "        \n",
    "        # Score components (0-100 scale)\n",
    "        # - Shared notebook usage (40 points)\n",
    "        # - Dashboard creation (30 points)\n",
    "        # - Git usage (30 points)\n",
    "        \n",
    "        notebook_score = min((shared_notebook_users / total_active) * 100, 40)\n",
    "        dashboard_score = min((dashboard_creators / total_active) * 100 * 0.75, 30)  # Scale down\n",
    "        git_score = min((git_users / total_active) * 100 * 0.75, 30) if git_users > 0 else 0  # Scale down\n",
    "        \n",
    "        collaboration_score = notebook_score + dashboard_score + git_score\n",
    "        \n",
    "        log(f\"\\n  Overall Collaboration Score: {collaboration_score:.1f}/100\")\n",
    "        log(f\"    Notebook collaboration: {notebook_score:.1f}/40\")\n",
    "        log(f\"    Dashboard sharing: {dashboard_score:.1f}/30\")\n",
    "        log(f\"    Git collaboration: {git_score:.1f}/30\")\n",
    "        \n",
    "        # Interpretation\n",
    "        if collaboration_score >= 70:\n",
    "            interpretation = \"EXCELLENT - High collaboration culture\"\n",
    "        elif collaboration_score >= 50:\n",
    "            interpretation = \"GOOD - Moderate collaboration\"\n",
    "        elif collaboration_score >= 30:\n",
    "            interpretation = \"FAIR - Some collaboration\"\n",
    "        else:\n",
    "            interpretation = \"LOW - Limited collaboration\"\n",
    "        \n",
    "        log(f\"\\n  Assessment: {interpretation}\")\n",
    "        \n",
    "        # 5. Collaboration Recommendations\n",
    "        log(\"\\n\uD83D\uDCA1 COLLABORATION RECOMMENDATIONS:\")\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        if notebook_score < 20:\n",
    "            recommendations.append(\"Promote shared notebook usage and /Shared folder\")\n",
    "        \n",
    "        if dashboard_score < 15:\n",
    "            recommendations.append(\"Encourage dashboard creation for team visibility\")\n",
    "        \n",
    "        if git_score < 10:\n",
    "            recommendations.append(\"Introduce Git integration for version control\")\n",
    "        \n",
    "        if len(recommendations) > 0:\n",
    "            for i, rec in enumerate(recommendations, 1):\n",
    "                log(f\"  {i}. {rec}\")\n",
    "        else:\n",
    "            log(\"  ✓ Collaboration practices look strong!\")\n",
    "        \n",
    "        # Store collaboration metrics\n",
    "        collaboration_metrics = {\n",
    "            'collaboration_score': collaboration_score,\n",
    "            'shared_notebook_users': shared_notebook_users,\n",
    "            'dashboard_creators': dashboard_creators,\n",
    "            'git_users': git_users,\n",
    "            'interpretation': interpretation\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        log(f\"❌ Error calculating collaboration score: {str(e)}\")\n",
    "        import traceback\n",
    "        log(traceback.format_exc())\n",
    "        collaboration_metrics = None\n",
    "else:\n",
    "    log(\"ℹ️  Insufficient data for collaboration analysis\")\n",
    "    collaboration_metrics = None\n",
    "\n",
    "log_execution_time(\"Collaboration Score\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "427cb16d-3bb6-4c3c-a111-5b75e9abf1c2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Calculate adoption metrics (DAU/WAU/MAU)"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"CALCULATING ADOPTION METRICS\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "if activity_df is not None and users_df is not None:\n",
    "    try:\n",
    "        # Calculate active users for different time periods\n",
    "        current_date = datetime.now(eastern).date()\n",
    "        \n",
    "        # Daily Active Users (DAU)\n",
    "        dau_date = current_date - timedelta(days=DAU_DAYS)\n",
    "        dau = activity_df.filter(F.col('activity_date') >= F.lit(dau_date)).select('user_name').distinct().count()\n",
    "        \n",
    "        # Weekly Active Users (WAU)\n",
    "        wau_date = current_date - timedelta(days=WAU_DAYS)\n",
    "        wau = activity_df.filter(F.col('activity_date') >= F.lit(wau_date)).select('user_name').distinct().count()\n",
    "        \n",
    "        # Monthly Active Users (MAU)\n",
    "        mau_date = current_date - timedelta(days=MAU_DAYS)\n",
    "        mau = activity_df.filter(F.col('activity_date') >= F.lit(mau_date)).select('user_name').distinct().count()\n",
    "        \n",
    "        # Total active users\n",
    "        total_active_users = users_df.filter(F.col('active') == True).count()\n",
    "        \n",
    "        log(f\"\\n\uD83D\uDCC8 Active User Metrics:\")\n",
    "        log(f\"  DAU (last {DAU_DAYS} day): {dau} ({(dau/total_active_users*100) if total_active_users > 0 else 0:.1f}% of active users)\")\n",
    "        log(f\"  WAU (last {WAU_DAYS} days): {wau} ({(wau/total_active_users*100) if total_active_users > 0 else 0:.1f}% of active users)\")\n",
    "        log(f\"  MAU (last {MAU_DAYS} days): {mau} ({(mau/total_active_users*100) if total_active_users > 0 else 0:.1f}% of active users)\")\n",
    "        \n",
    "        # Calculate user activity levels\n",
    "        user_activity = activity_df.groupBy('user_name').agg(\n",
    "            F.sum('activity_count').alias('total_activities'),\n",
    "            F.countDistinct('activity_date').alias('active_days'),\n",
    "            F.countDistinct('action_name').alias('unique_actions'),\n",
    "            F.max('activity_date').alias('last_activity_date')\n",
    "        )\n",
    "        \n",
    "        # Join with users\n",
    "        user_metrics = users_df.join(user_activity, 'user_name', 'left')\n",
    "        \n",
    "        # Fill nulls for users with no activity\n",
    "        user_metrics = user_metrics.fillna({\n",
    "            'total_activities': 0,\n",
    "            'active_days': 0,\n",
    "            'unique_actions': 0\n",
    "        })\n",
    "        \n",
    "        # Classify users\n",
    "        user_metrics = user_metrics.withColumn(\n",
    "            'user_segment',\n",
    "            F.when(F.col('total_activities') >= POWER_USER_THRESHOLD, 'Power User')\n",
    "             .when(F.col('total_activities') >= 10, 'Regular User')\n",
    "             .when(F.col('total_activities') >= 1, 'Occasional User')\n",
    "             .otherwise('Inactive')\n",
    "        )\n",
    "        \n",
    "        # Calculate days since last activity\n",
    "        user_metrics = user_metrics.withColumn(\n",
    "            'days_since_activity',\n",
    "            F.datediff(F.lit(current_date), F.col('last_activity_date'))\n",
    "        )\n",
    "        \n",
    "        log(f\"\\n\uD83D\uDC65 User Segmentation:\")\n",
    "        segments = user_metrics.groupBy('user_segment').count().orderBy(F.desc('count'))\n",
    "        for row in segments.collect():\n",
    "            log(f\"  {row.user_segment}: {row['count']} users\")\n",
    "        \n",
    "        # Inactive users\n",
    "        inactive_users = user_metrics.filter(\n",
    "            (F.col('days_since_activity') > INACTIVE_THRESHOLD_DAYS) | \n",
    "            (F.col('last_activity_date').isNull())\n",
    "        )\n",
    "        inactive_count = inactive_users.count()\n",
    "        \n",
    "        log(f\"\\n⚠️  Inactive users (>{INACTIVE_THRESHOLD_DAYS} days): {inactive_count}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        log(f\"✗ Error calculating metrics: {str(e)}\")\n",
    "        user_metrics = None\n",
    "        dau = wau = mau = 0\n",
    "else:\n",
    "    log(\"⚠️  Skipping metrics calculation (no data)\")\n",
    "    user_metrics = None\n",
    "    dau = wau = mau = 0\n",
    "\n",
    "log_execution_time(\"Calculate Metrics\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3c0502e-b748-4134-9009-b8aa2ab27fdb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Feature usage analysis"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"FEATURE USAGE ANALYSIS\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "if activity_df is not None:\n",
    "    try:\n",
    "        # Feature usage by action type\n",
    "        feature_usage = activity_df.groupBy('action_name', 'service_name').agg(\n",
    "            F.sum('activity_count').alias('total_uses'),\n",
    "            F.countDistinct('user_name').alias('unique_users')\n",
    "        ).orderBy(F.desc('total_uses'))\n",
    "        \n",
    "        # Map actions to feature categories and friendly names\n",
    "        feature_categories = {\n",
    "            # Notebooks\n",
    "            'runCommand': ('Notebooks', 'Notebook Execution'),\n",
    "            'submitCommand': ('Notebooks', 'Command Submission'),\n",
    "            'modifyNotebook': ('Notebooks', 'Notebook Editing'),\n",
    "            'createNotebook': ('Notebooks', 'Notebook Creation'),\n",
    "            'runNotebook': ('Notebooks', 'Notebook Runs'),\n",
    "            \n",
    "            # SQL\n",
    "            'executeQuery': ('SQL', 'Query Execution'),\n",
    "            'createQuery': ('SQL', 'Query Creation'),\n",
    "            'commandSubmit': ('SQL', 'SQL Command Submit'),\n",
    "            'commandFinish': ('SQL', 'SQL Command Finish'),\n",
    "            \n",
    "            # Genie/AI (by service name)\n",
    "            'agents': ('Genie/AI', 'AI Agents'),\n",
    "            'knowledge_assistant': ('Genie/AI', 'Knowledge Assistant'),\n",
    "            'supervisor_agent': ('Genie/AI', 'Supervisor Agent'),\n",
    "            'agentFramework': ('Genie/AI', 'Agent Framework'),\n",
    "            'agentEvaluation': ('Genie/AI', 'Agent Evaluation'),\n",
    "            'aibiGenie': ('Genie/AI', 'AI/BI Genie'),\n",
    "            \n",
    "            # Dashboards\n",
    "            'createDashboard': ('Dashboards', 'Dashboard Creation'),\n",
    "            'viewDashboard': ('Dashboards', 'Dashboard Views'),\n",
    "            'modifyDashboard': ('Dashboards', 'Dashboard Editing'),\n",
    "            \n",
    "            # Jobs\n",
    "            'createJob': ('Jobs', 'Job Creation'),\n",
    "            'runJob': ('Jobs', 'Job Execution'),\n",
    "            'submitRun': ('Jobs', 'Job Submission'),\n",
    "            \n",
    "            # Git/Repos\n",
    "            'gitSync': ('Git/Repos', 'Git Sync'),\n",
    "            'gitCommit': ('Git/Repos', 'Git Commit'),\n",
    "            'gitPush': ('Git/Repos', 'Git Push'),\n",
    "            \n",
    "            # MLflow\n",
    "            'mlflowRunCreated': ('MLflow', 'Experiment Runs'),\n",
    "            'mlflowModelRegistered': ('MLflow', 'Model Registration'),\n",
    "        }\n",
    "        \n",
    "        # Collect feature usage data\n",
    "        feature_data = []\n",
    "        for row in feature_usage.collect():\n",
    "            # Check if it's a Genie/AI service\n",
    "            if row.service_name in ['agents', 'knowledge_assistant', 'supervisor_agent', \n",
    "                                     'agentFramework', 'agentEvaluation', 'aibiGenie']:\n",
    "                category, feature_name = feature_categories.get(row.service_name, ('Other', row.service_name))\n",
    "            else:\n",
    "                category, feature_name = feature_categories.get(row.action_name, ('Other', row.action_name))\n",
    "            \n",
    "            feature_data.append({\n",
    "                'category': category,\n",
    "                'feature_name': feature_name,\n",
    "                'action_name': row.action_name,\n",
    "                'service_name': row.service_name,\n",
    "                'total_uses': row.total_uses,\n",
    "                'unique_users': row.unique_users\n",
    "            })\n",
    "        \n",
    "        # Convert to pandas for easier grouping\n",
    "        import pandas as pd\n",
    "        features_pd = pd.DataFrame(feature_data)\n",
    "        \n",
    "        # Calculate total active users\n",
    "        total_active = users_df.filter(F.col('active') == True).count()\n",
    "        \n",
    "        # Group by category\n",
    "        log(f\"\\n\uD83D\uDCCA FEATURE ADOPTION BY CATEGORY:\")\n",
    "        log(\"=\"*60)\n",
    "        \n",
    "        category_summary = features_pd.groupby('category').agg({\n",
    "            'total_uses': 'sum',\n",
    "            'unique_users': 'max'  # Max because same user can appear in multiple features\n",
    "        }).sort_values('total_uses', ascending=False)\n",
    "        \n",
    "        for category, row in category_summary.iterrows():\n",
    "            adoption_rate = (row['unique_users'] / total_active * 100) if total_active > 0 else 0\n",
    "            log(f\"\\n{category}:\")\n",
    "            log(f\"  Total uses: {int(row['total_uses']):,}\")\n",
    "            log(f\"  Unique users: {int(row['unique_users'])} ({adoption_rate:.1f}% adoption)\")\n",
    "            \n",
    "            # Show top features in this category\n",
    "            category_features = features_pd[features_pd['category'] == category].sort_values('total_uses', ascending=False).head(5)\n",
    "            log(f\"  Top features:\")\n",
    "            for _, feat in category_features.iterrows():\n",
    "                feat_adoption = (feat['unique_users'] / total_active * 100) if total_active > 0 else 0\n",
    "                log(f\"    • {feat['feature_name']}: {int(feat['total_uses']):,} uses, {int(feat['unique_users'])} users ({feat_adoption:.1f}%)\")\n",
    "        \n",
    "        # Overall summary\n",
    "        log(f\"\\n\" + \"=\"*60)\n",
    "        log(f\"\uD83D\uDCC8 OVERALL ADOPTION SUMMARY:\")\n",
    "        log(f\"  Total active users: {total_active}\")\n",
    "        log(f\"  Total feature uses: {int(features_pd['total_uses'].sum()):,}\")\n",
    "        log(f\"  Average uses per user: {int(features_pd['total_uses'].sum() / total_active) if total_active > 0 else 0:,}\")\n",
    "        \n",
    "        # Category adoption ranking\n",
    "        log(f\"\\n\uD83C\uDFC6 Category Adoption Ranking:\")\n",
    "        for i, (category, row) in enumerate(category_summary.iterrows(), 1):\n",
    "            adoption_rate = (row['unique_users'] / total_active * 100) if total_active > 0 else 0\n",
    "            log(f\"  {i}. {category}: {adoption_rate:.1f}% ({int(row['unique_users'])}/{total_active} users)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        log(f\"✗ Error analyzing feature usage: {str(e)}\")\n",
    "        import traceback\n",
    "        log(traceback.format_exc())\n",
    "        feature_usage = None\n",
    "else:\n",
    "    log(\"⚠️  Skipping feature analysis (no activity data)\")\n",
    "    feature_usage = None\n",
    "\n",
    "log_execution_time(\"Feature Analysis\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e971f9f4-8e3b-4112-a55d-ca7604755a93",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Generate recommendations"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"GENERATING RECOMMENDATIONS\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "if user_metrics is not None:\n",
    "    # Inactive users\n",
    "    inactive_users_list = inactive_users.collect() if 'inactive_users' in dir() else []\n",
    "    \n",
    "    if len(inactive_users_list) > 0:\n",
    "        recommendations.append({\n",
    "            'priority': 'MEDIUM',\n",
    "            'category': 'User Management',\n",
    "            'issue': f'{len(inactive_users_list)} inactive users (>{INACTIVE_THRESHOLD_DAYS} days)',\n",
    "            'impact': 'Unused licenses, security risk from stale accounts',\n",
    "            'recommendation': f'Review and deactivate {len(inactive_users_list)} inactive user accounts',\n",
    "            'affected_count': len(inactive_users_list)\n",
    "        })\n",
    "    \n",
    "    # Low AI adoption\n",
    "    if 'agent_adoption_rate' in dir() and agent_adoption_rate < 20:\n",
    "        recommendations.append({\n",
    "            'priority': 'LOW',\n",
    "            'category': 'AI Adoption',\n",
    "            'issue': f'Low AI assistant adoption: {agent_adoption_rate:.1f}%',\n",
    "            'impact': 'Users not leveraging productivity features',\n",
    "            'recommendation': 'Promote AI assistant through training sessions and demos',\n",
    "            'affected_count': int(total_active_users * (100 - agent_adoption_rate) / 100) if 'total_active_users' in dir() else 0\n",
    "        })\n",
    "    \n",
    "    # Users with low activity\n",
    "    low_activity_users = user_metrics.filter(\n",
    "        (F.col('total_activities') > 0) & \n",
    "        (F.col('total_activities') < 5) &\n",
    "        (F.col('active') == True)\n",
    "    )\n",
    "    low_activity_count = low_activity_users.count()\n",
    "    \n",
    "    if low_activity_count > 0:\n",
    "        recommendations.append({\n",
    "            'priority': 'LOW',\n",
    "            'category': 'Training',\n",
    "            'issue': f'{low_activity_count} users with minimal activity (<5 actions)',\n",
    "            'impact': 'Low platform utilization, potential training gap',\n",
    "            'recommendation': 'Provide onboarding training and resources',\n",
    "            'affected_count': low_activity_count\n",
    "        })\n",
    "    \n",
    "    # Create recommendations DataFrame\n",
    "    if recommendations:\n",
    "        recommendations_df = spark.createDataFrame(recommendations)\n",
    "        \n",
    "        log(f\"\\n\uD83D\uDCA1 Generated {len(recommendations)} recommendations:\")\n",
    "        for rec in recommendations:\n",
    "            log(f\"  {rec['priority']}: {rec['issue']}\")\n",
    "    else:\n",
    "        recommendations_df = None\n",
    "        log(\"\\n✅ No recommendations - adoption looks healthy!\")\n",
    "else:\n",
    "    log(\"⚠️  Skipping recommendations (no data)\")\n",
    "    recommendations_df = None\n",
    "\n",
    "log_execution_time(\"Generate Recommendations\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c504c97e-c8a5-432b-b0fe-0f7a8edb6dc9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Visualizations (interactive mode only)"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "if not is_job_mode and ENABLE_VISUALIZATIONS and user_metrics is not None:\n",
    "    log(\"\\n\" + \"=\"*60)\n",
    "    log(\"VISUALIZATIONS\")\n",
    "    log(\"=\"*60)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    # Create figure with subplots (3 rows, 3 columns for 9 charts)\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(20, 18))\n",
    "    \n",
    "    # Chart 1: User Segmentation\n",
    "    ax1 = axes[0, 0]\n",
    "    segments = user_metrics.groupBy('user_segment').count().toPandas()\n",
    "    colors = {'Power User': 'green', 'Regular User': 'steelblue', 'Occasional User': 'orange', 'Inactive': 'red'}\n",
    "    bar_colors = [colors.get(seg, 'gray') for seg in segments['user_segment']]\n",
    "    bars = ax1.bar(segments['user_segment'], segments['count'], color=bar_colors)\n",
    "    ax1.set_title('User Segmentation', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlabel('User Segment')\n",
    "    ax1.set_ylabel('Number of Users')\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    for i, (bar, count) in enumerate(zip(bars, segments['count'])):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                str(int(count)), ha='center', fontweight='bold')\n",
    "    \n",
    "    # Chart 2: Active Users Trend (DAU/WAU/MAU)\n",
    "    ax2 = axes[0, 1]\n",
    "    active_metrics = ['DAU', 'WAU', 'MAU']\n",
    "    active_counts = [dau, wau, mau]\n",
    "    ax2.bar(active_metrics, active_counts, color=['lightgreen', 'steelblue', 'darkblue'])\n",
    "    ax2.set_title('Active Users Metrics', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Number of Users')\n",
    "    for i, v in enumerate(active_counts):\n",
    "        ax2.text(i, v + 1, str(v), ha='center', fontweight='bold')\n",
    "    \n",
    "    # Chart 3: AI Adoption Funnel (NEW)\n",
    "    ax3 = axes[0, 2]\n",
    "    if 'ai_metrics_summary' in dir() and ai_metrics_summary is not None:\n",
    "        # Get AI funnel data from the AI breakdown analysis\n",
    "        funnel_labels = ['Tried Once', 'Light\\n(2-5)', 'Regular\\n(6-20)', 'Power\\n(20+)']\n",
    "        # Calculate from agent_usage if available\n",
    "        if 'agent_usage' in dir() and agent_usage is not None:\n",
    "            tried_once = agent_usage.filter(F.col('agent_interactions') == 1).count()\n",
    "            light_users = agent_usage.filter((F.col('agent_interactions') >= 2) & (F.col('agent_interactions') <= 5)).count()\n",
    "            regular_users = agent_usage.filter((F.col('agent_interactions') >= 6) & (F.col('agent_interactions') <= 20)).count()\n",
    "            power_users = agent_usage.filter(F.col('agent_interactions') > 20).count()\n",
    "            funnel_values = [tried_once, light_users, regular_users, power_users]\n",
    "            funnel_colors = ['lightcoral', 'orange', 'steelblue', 'green']\n",
    "            bars = ax3.bar(range(len(funnel_labels)), funnel_values, color=funnel_colors)\n",
    "            ax3.set_xticks(range(len(funnel_labels)))\n",
    "            ax3.set_xticklabels(funnel_labels, fontsize=9)\n",
    "            ax3.set_title('AI Adoption Funnel', fontsize=12, fontweight='bold')\n",
    "            ax3.set_ylabel('Number of Users')\n",
    "            for bar, val in zip(bars, funnel_values):\n",
    "                height = bar.get_height()\n",
    "                ax3.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                        str(int(val)), ha='center', fontweight='bold', fontsize=9)\n",
    "        else:\n",
    "            ax3.text(0.5, 0.5, 'AI data not available', ha='center', va='center', transform=ax3.transAxes)\n",
    "            ax3.axis('off')\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'AI data not available', ha='center', va='center', transform=ax3.transAxes)\n",
    "        ax3.axis('off')\n",
    "    \n",
    "    # Chart 4: Feature Usage Distribution (with logarithmic scale)\n",
    "    ax4 = axes[1, 0]\n",
    "    if feature_usage is not None and feature_usage.count() > 0:\n",
    "        top_features = feature_usage.limit(10).toPandas()\n",
    "        top_features['total_uses'] = top_features['total_uses'].apply(lambda x: max(x, 0.1))\n",
    "        ax4.barh(range(len(top_features)), top_features['total_uses'], color='steelblue')\n",
    "        ax4.set_yticks(range(len(top_features)))\n",
    "        ax4.set_yticklabels(top_features['action_name'], fontsize=8)\n",
    "        ax4.set_title('Top Features by Usage (Log Scale)', fontsize=12, fontweight='bold')\n",
    "        ax4.set_xlabel('Relative Usage (log scale)')\n",
    "        ax4.set_xscale('log')\n",
    "        ax4.set_xticklabels([])\n",
    "        ax4.invert_yaxis()\n",
    "    \n",
    "    # Chart 5: AI/Agent Adoption\n",
    "    ax5 = axes[1, 1]\n",
    "    if 'agent_adoption_rate' in dir():\n",
    "        adoption_data = ['Using AI', 'Not Using AI']\n",
    "        adoption_counts = [\n",
    "            agent_usage.count() if agent_usage is not None else 0,\n",
    "            total_active_users - (agent_usage.count() if agent_usage is not None else 0)\n",
    "        ]\n",
    "        colors_pie = ['green', 'lightgray']\n",
    "        ax5.pie(adoption_counts, labels=adoption_data, autopct='%1.1f%%', colors=colors_pie, startangle=90)\n",
    "        ax5.set_title(f'AI/Agent Adoption Rate: {agent_adoption_rate:.1f}%', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Chart 6: User Journey Entry Points (NEW)\n",
    "    ax6 = axes[1, 2]\n",
    "    if 'journey_metrics' in dir() and journey_metrics is not None:\n",
    "        entry_labels = ['Notebooks', 'SQL', 'AI']\n",
    "        entry_values = [\n",
    "            journey_metrics.get('notebook_starters', 0),\n",
    "            journey_metrics.get('sql_starters', 0),\n",
    "            journey_metrics.get('ai_starters', 0)\n",
    "        ]\n",
    "        entry_colors = ['steelblue', 'orange', 'green']\n",
    "        bars = ax6.bar(entry_labels, entry_values, color=entry_colors)\n",
    "        ax6.set_title('User Journey Entry Points', fontsize=12, fontweight='bold')\n",
    "        ax6.set_ylabel('Number of Users')\n",
    "        for bar, val in zip(bars, entry_values):\n",
    "            height = bar.get_height()\n",
    "            ax6.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    str(int(val)), ha='center', fontweight='bold')\n",
    "    else:\n",
    "        ax6.text(0.5, 0.5, 'Journey data not available', ha='center', va='center', transform=ax6.transAxes)\n",
    "        ax6.axis('off')\n",
    "    \n",
    "    # Chart 7: Top Users by Classification (with logarithmic scale)\n",
    "    ax7 = axes[2, 0]\n",
    "    top_users_by_segment = []\n",
    "    segment_colors_map = {'Power User': 'green', 'Regular User': 'steelblue', 'Occasional User': 'orange', 'Inactive': 'red'}\n",
    "    \n",
    "    for segment in ['Power User', 'Regular User', 'Occasional User', 'Inactive']:\n",
    "        segment_users = user_metrics.filter(F.col('user_segment') == segment) \\\n",
    "            .orderBy(F.desc('total_activities')) \\\n",
    "            .limit(5) \\\n",
    "            .select('user_name', 'total_activities', 'user_segment') \\\n",
    "            .collect()\n",
    "        \n",
    "        for user in segment_users:\n",
    "            top_users_by_segment.append({\n",
    "                'user': user.user_name.split('@')[0] if '@' in user.user_name else user.user_name,\n",
    "                'activities': user.total_activities if user.total_activities > 0 else 0.1,\n",
    "                'segment': user.user_segment,\n",
    "                'color': segment_colors_map.get(segment, 'gray')\n",
    "            })\n",
    "    \n",
    "    if top_users_by_segment:\n",
    "        y_pos = 0\n",
    "        y_labels = []\n",
    "        y_positions = []\n",
    "        \n",
    "        for segment in ['Power User', 'Regular User', 'Occasional User', 'Inactive']:\n",
    "            segment_data = [u for u in top_users_by_segment if u['segment'] == segment]\n",
    "            \n",
    "            if segment_data:\n",
    "                y_labels.append(f\"--- {segment} ---\")\n",
    "                y_positions.append(y_pos)\n",
    "                y_pos += 1\n",
    "                \n",
    "                for user_data in segment_data:\n",
    "                    ax7.barh(y_pos, user_data['activities'], color=user_data['color'], alpha=0.7)\n",
    "                    y_labels.append(user_data['user'][:20])\n",
    "                    y_positions.append(y_pos)\n",
    "                    y_pos += 1\n",
    "                \n",
    "                y_pos += 0.5\n",
    "        \n",
    "        ax7.set_yticks(y_positions)\n",
    "        ax7.set_yticklabels(y_labels, fontsize=7)\n",
    "        ax7.set_title('Top 5 Users by Classification', fontsize=12, fontweight='bold')\n",
    "        ax7.set_xlabel('Activity (log scale)')\n",
    "        ax7.set_xscale('log')\n",
    "        ax7.set_xticklabels([])\n",
    "        ax7.invert_yaxis()\n",
    "    \n",
    "    # Chart 8: Feature Adoption by Category\n",
    "    ax8 = axes[2, 1]\n",
    "    if 'features_pd' in dir() and features_pd is not None and len(features_pd) > 0:\n",
    "        category_summary = features_pd.groupby('category').agg({\n",
    "            'unique_users': 'max'\n",
    "        }).sort_values('unique_users', ascending=True)\n",
    "        \n",
    "        total_active = users_df.filter(F.col('active') == True).count()\n",
    "        category_summary['adoption_rate'] = (category_summary['unique_users'] / total_active * 100) if total_active > 0 else 0\n",
    "        \n",
    "        categories = category_summary.index.tolist()\n",
    "        adoption_rates = category_summary['adoption_rate'].tolist()\n",
    "        \n",
    "        bar_colors_adoption = ['green' if rate >= 50 else 'steelblue' if rate >= 25 else 'orange' for rate in adoption_rates]\n",
    "        \n",
    "        bars = ax8.barh(categories, adoption_rates, color=bar_colors_adoption)\n",
    "        ax8.set_title('Feature Adoption by Category', fontsize=12, fontweight='bold')\n",
    "        ax8.set_xlabel('Adoption Rate (%)')\n",
    "        ax8.set_xlim(0, 100)\n",
    "        \n",
    "        for i, (bar, rate, users) in enumerate(zip(bars, adoption_rates, category_summary['unique_users'])):\n",
    "            width = bar.get_width()\n",
    "            ax8.text(width + 2, bar.get_y() + bar.get_height()/2.,\n",
    "                    f'{rate:.1f}% ({int(users)})',\n",
    "                    ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "    else:\n",
    "        ax8.text(0.5, 0.5, 'Category data not available', ha='center', va='center', transform=ax8.transAxes)\n",
    "        ax8.axis('off')\n",
    "    \n",
    "    # Chart 9: Collaboration Score Breakdown (NEW)\n",
    "    ax9 = axes[2, 2]\n",
    "    if 'collaboration_metrics' in dir() and collaboration_metrics is not None:\n",
    "        # Create stacked bar showing collaboration score components\n",
    "        components = ['Notebooks\\n(40 pts)', 'Dashboards\\n(30 pts)', 'Git\\n(30 pts)']\n",
    "        \n",
    "        # Calculate actual scores from collaboration_metrics\n",
    "        total_active = users_df.filter(F.col('active') == True).count()\n",
    "        shared_notebook_users = collaboration_metrics.get('shared_notebook_users', 0)\n",
    "        dashboard_creators = collaboration_metrics.get('dashboard_creators', 0)\n",
    "        git_users = collaboration_metrics.get('git_users', 0)\n",
    "        \n",
    "        notebook_score = min((shared_notebook_users / total_active) * 100, 40) if total_active > 0 else 0\n",
    "        dashboard_score = min((dashboard_creators / total_active) * 100 * 0.75, 30) if total_active > 0 else 0\n",
    "        git_score = min((git_users / total_active) * 100 * 0.75, 30) if total_active > 0 and git_users > 0 else 0\n",
    "        \n",
    "        scores = [notebook_score, dashboard_score, git_score]\n",
    "        max_scores = [40, 30, 30]\n",
    "        \n",
    "        # Create bars\n",
    "        x_pos = np.arange(len(components))\n",
    "        bars1 = ax9.bar(x_pos, scores, color=['green', 'steelblue', 'orange'], alpha=0.8, label='Actual')\n",
    "        bars2 = ax9.bar(x_pos, [m - s for m, s in zip(max_scores, scores)], \n",
    "                       bottom=scores, color='lightgray', alpha=0.3, label='Potential')\n",
    "        \n",
    "        ax9.set_xticks(x_pos)\n",
    "        ax9.set_xticklabels(components, fontsize=9)\n",
    "        ax9.set_ylabel('Score')\n",
    "        ax9.set_title(f'Collaboration Score: {collaboration_metrics.get(\"collaboration_score\", 0):.1f}/100', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax9.legend(loc='upper right', fontsize=8)\n",
    "        \n",
    "        # Add score labels\n",
    "        for bar, score in zip(bars1, scores):\n",
    "            height = bar.get_height()\n",
    "            ax9.text(bar.get_x() + bar.get_width()/2., height/2,\n",
    "                    f'{score:.1f}', ha='center', va='center', fontweight='bold', fontsize=9)\n",
    "    else:\n",
    "        ax9.text(0.5, 0.5, 'Collaboration data not available', ha='center', va='center', transform=ax9.transAxes)\n",
    "        ax9.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    log(\"✓ Visualizations generated (9 charts)\")\n",
    "else:\n",
    "    if is_job_mode:\n",
    "        log(\"ℹ️  Visualizations skipped (job mode)\")\n",
    "    else:\n",
    "        log(\"ℹ️  Visualizations skipped (no data or disabled)\")\n",
    "\n",
    "log_execution_time(\"Visualizations\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32ab52e0-2e5c-4555-9f9f-aa4577ee6977",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Export to Excel"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "if ENABLE_EXCEL_EXPORT and user_metrics is not None:\n",
    "    log(\"\\n\" + \"=\"*60)\n",
    "    log(\"EXPORTING TO EXCEL\")\n",
    "    log(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Create export directory\n",
    "        if is_serverless:\n",
    "            import tempfile\n",
    "            temp_dir = tempfile.mkdtemp()\n",
    "            export_path = temp_dir\n",
    "        else:\n",
    "            export_path = EXPORT_PATH\n",
    "            os.makedirs(export_path, exist_ok=True)\n",
    "        \n",
    "        timestamp = datetime.now(eastern).strftime('%Y%m%d_%H%M%S')\n",
    "        excel_path = f\"{export_path}/adoption_report_{timestamp}.xlsx\"\n",
    "        \n",
    "        log(f\"Creating Excel workbook: {excel_path}\")\n",
    "        \n",
    "        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "            # Sheet 1: User Metrics\n",
    "            user_metrics.orderBy(F.desc('total_activities')).toPandas().to_excel(writer, sheet_name='User Metrics', index=False)\n",
    "            \n",
    "            # Sheet 2: AI/Agent Users\n",
    "            if agent_usage is not None:\n",
    "                agent_usage.orderBy(F.desc('agent_interactions')).toPandas().to_excel(writer, sheet_name='AI Agent Users', index=False)\n",
    "            \n",
    "            # Sheet 3: Feature Usage\n",
    "            if feature_usage is not None:\n",
    "                feature_usage.toPandas().to_excel(writer, sheet_name='Feature Usage', index=False)\n",
    "            \n",
    "            # Sheet 4: Inactive Users\n",
    "            if 'inactive_users' in dir() and inactive_users is not None:\n",
    "                inactive_users.toPandas().to_excel(writer, sheet_name='Inactive Users', index=False)\n",
    "            \n",
    "            # Sheet 5: Recommendations\n",
    "            if recommendations_df is not None:\n",
    "                recommendations_df.toPandas().to_excel(writer, sheet_name='Recommendations', index=False)\n",
    "            \n",
    "            # Sheet 6: Summary\n",
    "            summary_data = {\n",
    "                'Metric': [\n",
    "                    'Total Users',\n",
    "                    'Active Users',\n",
    "                    'DAU',\n",
    "                    'WAU',\n",
    "                    'MAU',\n",
    "                    'AI/Agent Adoption Rate (%)',\n",
    "                    'Power Users',\n",
    "                    'Inactive Users',\n",
    "                    'Analysis Period (days)',\n",
    "                    'Analysis Date'\n",
    "                ],\n",
    "                'Value': [\n",
    "                    users_df.count(),\n",
    "                    users_df.filter(F.col('active') == True).count(),\n",
    "                    dau,\n",
    "                    wau,\n",
    "                    mau,\n",
    "                    f\"{agent_adoption_rate:.1f}\" if 'agent_adoption_rate' in dir() else '0',\n",
    "                    user_metrics.filter(F.col('user_segment') == 'Power User').count(),\n",
    "                    inactive_count if 'inactive_count' in dir() else 0,\n",
    "                    LOOKBACK_DAYS,\n",
    "                    datetime.now(eastern).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                ]\n",
    "            }\n",
    "            pd.DataFrame(summary_data).to_excel(writer, sheet_name='Summary', index=False)\n",
    "        \n",
    "        # Apply formatting\n",
    "        from openpyxl import load_workbook\n",
    "        from openpyxl.styles import Font, PatternFill, Alignment\n",
    "        \n",
    "        wb = load_workbook(excel_path)\n",
    "        for sheet_name in wb.sheetnames:\n",
    "            ws = wb[sheet_name]\n",
    "            \n",
    "            # Format header row\n",
    "            for cell in ws[1]:\n",
    "                cell.font = Font(bold=True, color='FFFFFF')\n",
    "                cell.fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')\n",
    "                cell.alignment = Alignment(horizontal='center')\n",
    "            \n",
    "            # Auto-adjust column widths\n",
    "            for column in ws.columns:\n",
    "                max_length = 0\n",
    "                column_letter = column[0].column_letter\n",
    "                for cell in column:\n",
    "                    if cell.value:\n",
    "                        max_length = max(max_length, len(str(cell.value)))\n",
    "                ws.column_dimensions[column_letter].width = min(max_length + 2, 50)\n",
    "        \n",
    "        wb.save(excel_path)\n",
    "        \n",
    "        log(f\"✓ Excel workbook created: {excel_path}\")\n",
    "        log(f\"  Sheets: {len(wb.sheetnames)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        log(f\"✗ Excel export failed: {str(e)}\")\n",
    "else:\n",
    "    log(\"ℹ️  Excel export skipped\")\n",
    "\n",
    "log_execution_time(\"Excel Export\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7286b8da-1c90-45e3-b94b-a5139c837997",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Export to Delta table"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "if ENABLE_DELTA_EXPORT and user_metrics is not None:\n",
    "    log(\"\\n\" + \"=\"*60)\n",
    "    log(\"EXPORTING TO DELTA TABLE\")\n",
    "    log(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Add audit metadata\n",
    "        user_metrics_export = user_metrics.withColumn('audit_timestamp', F.current_timestamp())\n",
    "        user_metrics_export = user_metrics_export.withColumn('lookback_days', F.lit(LOOKBACK_DAYS))\n",
    "        user_metrics_export = user_metrics_export.withColumn('dau', F.lit(dau))\n",
    "        user_metrics_export = user_metrics_export.withColumn('wau', F.lit(wau))\n",
    "        user_metrics_export = user_metrics_export.withColumn('mau', F.lit(mau))\n",
    "        user_metrics_export = user_metrics_export.withColumn('agent_adoption_rate', F.lit(agent_adoption_rate if 'agent_adoption_rate' in dir() else 0))\n",
    "        \n",
    "        # Write to Delta table (append mode)\n",
    "        user_metrics_export.write \\\n",
    "            .format('delta') \\\n",
    "            .mode('append') \\\n",
    "            .option('mergeSchema', 'true') \\\n",
    "            .saveAsTable(DELTA_TABLE_NAME)\n",
    "        \n",
    "        log(f\"✓ Delta table updated: {DELTA_TABLE_NAME}\")\n",
    "        log(f\"  Mode: append (historical retention)\")\n",
    "        log(f\"  Rows added: {user_metrics.count()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        log(f\"✗ Delta export failed: {str(e)}\")\n",
    "else:\n",
    "    log(\"ℹ️  Delta export skipped\")\n",
    "\n",
    "log_execution_time(\"Delta Export\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41dc542b-73e2-4fc8-87cb-529eeef0888f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Execution summary"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXECUTION SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "execution_time = time.time() - execution_stats['start_time']\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"EXECUTION SUMMARY\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "log(f\"\\n⏱️  Total execution time: {execution_time:.2f} seconds\")\n",
    "\n",
    "log(f\"\\n\uD83D\uDCCA Statistics:\")\n",
    "log(f\"  Users analyzed: {execution_stats['users_processed']}\")\n",
    "log(f\"  Audit records processed: {execution_stats['audit_records_processed']:,}\")\n",
    "log(f\"  API calls: {execution_stats['api_calls']}\")\n",
    "log(f\"  API failures: {execution_stats['api_failures']}\")\n",
    "\n",
    "if user_metrics is not None:\n",
    "    log(f\"\\n\uD83D\uDC65 Adoption Summary:\")\n",
    "    log(f\"  DAU: {dau}\")\n",
    "    log(f\"  WAU: {wau}\")\n",
    "    log(f\"  MAU: {mau}\")\n",
    "    if 'agent_adoption_rate' in dir():\n",
    "        log(f\"  AI/Agent adoption: {agent_adoption_rate:.1f}%\")\n",
    "    log(f\"  Power users: {user_metrics.filter(F.col('user_segment') == 'Power User').count()}\")\n",
    "    log(f\"  Inactive users: {inactive_count if 'inactive_count' in dir() else 0}\")\n",
    "\n",
    "if recommendations_df is not None:\n",
    "    log(f\"\\n\uD83D\uDCA1 Recommendations: {recommendations_df.count()}\")\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"✓ COLLABORATION & ADOPTION ANALYSIS COMPLETE\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "# Return JSON summary for job mode\n",
    "if is_job_mode:\n",
    "    import json\n",
    "    summary = {\n",
    "        'status': 'success',\n",
    "        'execution_time_seconds': execution_time,\n",
    "        'users_analyzed': execution_stats['users_processed'],\n",
    "        'dau': dau,\n",
    "        'wau': wau,\n",
    "        'mau': mau,\n",
    "        'agent_adoption_rate': agent_adoption_rate if 'agent_adoption_rate' in dir() else 0,\n",
    "        'inactive_users': inactive_count if 'inactive_count' in dir() else 0,\n",
    "        'recommendations': recommendations_df.count() if recommendations_df is not None else 0,\n",
    "        'timestamp': datetime.now(eastern).isoformat()\n",
    "    }\n",
    "    dbutils.notebook.exit(json.dumps(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "366f5feb-6f6c-40fd-ac47-3550d71e88ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Collaboration & Adoption Monitor",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}