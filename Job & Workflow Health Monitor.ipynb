{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "842f58d7-6b09-434d-afbc-d3544a2cc89b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks Job & Workflow Health Monitor\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides a **comprehensive health assessment** of all Databricks jobs and workflows by analyzing job configurations, run history, success rates, execution times, failure patterns, and resource utilization. The output includes detailed reports identifying problematic jobs, performance bottlenecks, optimization opportunities, and actionable recommendations.\n",
    "\n",
    "**✨ Enterprise-grade job monitoring with success rate tracking, SLA violation detection, failure analysis, and performance optimization recommendations.**\n",
    "\n",
    "---\n",
    "\n",
    "## Features\n",
    "\n",
    "### Core Functionality\n",
    "* **Job Inventory**: Complete list of all jobs with metadata\n",
    "* **Run History Analysis**: Analyzes job runs over configurable time period (default: 30 days)\n",
    "* **Success Rate Tracking**: Calculates success/failure rates per job\n",
    "* **Execution Time Analysis**: Average, min, max, trend analysis\n",
    "* **Failure Pattern Detection**: Identifies common failure reasons\n",
    "* **SLA Violation Detection**: Flags jobs exceeding execution time thresholds\n",
    "* **Orphaned Job Detection**: Jobs with inactive or missing owners\n",
    "* **Retry Analysis**: Jobs with excessive retry attempts\n",
    "\n",
    "### Health Metrics\n",
    "* **Overall Health Score**: 0-100 score based on success rates and performance\n",
    "* **Job Status Distribution**: Active, paused, failed jobs\n",
    "* **Success Rate by Job**: Individual job performance tracking\n",
    "* **Execution Time Trends**: Identify degrading performance\n",
    "* **Failure Rate Trends**: Spot increasing failure patterns\n",
    "* **Resource Utilization**: Cluster usage, DBU consumption patterns\n",
    "\n",
    "### Analysis & Insights\n",
    "* **Problem Jobs**: High failure rate (>20%), slow execution, frequent retries\n",
    "* **At-Risk Jobs**: Declining success rates, increasing execution times\n",
    "* **Optimization Opportunities**: Over-provisioned clusters, inefficient schedules\n",
    "* **Dependency Analysis**: Job dependencies and potential bottlenecks\n",
    "* **Schedule Analysis**: Overlapping jobs, peak usage times\n",
    "* **Owner Analysis**: Jobs per owner, orphaned jobs\n",
    "\n",
    "### Recommendations\n",
    "* **Critical Issues**: Jobs failing >50% of runs\n",
    "* **Performance Issues**: Jobs with 2x+ execution time increase\n",
    "* **Configuration Issues**: Missing retries, no timeout, no alerts\n",
    "* **Optimization Suggestions**: Cluster right-sizing, schedule optimization\n",
    "\n",
    "### Export Formats\n",
    "* **Delta Table**: Historical tracking with append mode\n",
    "* **Excel Workbook**: Multi-sheet report with:\n",
    "  * Job Inventory\n",
    "  * Run History Summary\n",
    "  * Problem Jobs\n",
    "  * Health Metrics\n",
    "  * Recommendations\n",
    "  * Execution Statistics\n",
    "* **Interactive Visualizations**: Success rate trends, execution time charts\n",
    "\n",
    "---\n",
    "\n",
    "## Version Control\n",
    "\n",
    "| Version | Date | Author | Changes |\n",
    "|---------|------|--------|---------|  \n",
    "| 1.0.0 | 2026-02-16 | Assistant | Comprehensive job and workflow health monitoring system with complete coverage of all workspace jobs. Features include: job inventory with metadata (name, owner, schedule, cluster config), run history analysis (configurable lookback period, default 30 days), success rate calculation per job, execution time analysis (average, min, max, percentiles, trends), failure pattern detection and categorization, SLA violation detection (configurable thresholds), orphaned job identification, retry analysis, health scoring (0-100 weighted system), problem job identification (high failure rate >20%, slow execution, excessive retries), at-risk job detection (declining trends), optimization recommendations (cluster right-sizing, schedule conflicts), dependency analysis, schedule overlap detection, owner analysis, multiple export formats (Delta table with historical append, Excel multi-sheet workbook), interactive visualizations (matplotlib charts), job mode support with automatic configuration, serverless compute optimization, parallel API calls with ThreadPoolExecutor, retry logic with exponential backoff, progress tracking, execution statistics, configuration validation, and comprehensive error handling. |\n",
    "\n",
    "---\n",
    "\n",
    "## Configuration\n",
    "\n",
    "### Widget Parameters:\n",
    "* `lookback_days` - Days of run history to analyze (default: 30)\n",
    "* `failure_threshold` - Failure rate % to flag as problem (default: 20)\n",
    "* `slow_job_threshold_minutes` - Execution time threshold for slow jobs (default: 60)\n",
    "* `output_catalog` - Target catalog for Delta table (default: main)\n",
    "* `output_schema` - Target schema for Delta table (default: default)\n",
    "\n",
    "### Performance Settings:\n",
    "* `MAX_JOBS = 999` - Maximum jobs to analyze (999 = all)\n",
    "* `MAX_RUNS_PER_JOB = 100` - Maximum runs to analyze per job\n",
    "* `MAX_WORKERS = 10` - Parallel threads for API calls\n",
    "* `MAX_RETRIES = 3` - Retries for failed API calls\n",
    "* `RETRY_DELAY = 2` - Seconds between retries\n",
    "\n",
    "### Export Settings:\n",
    "* `ENABLE_EXCEL_EXPORT = True` - Excel workbook generation\n",
    "* `ENABLE_DELTA_EXPORT = True` - Delta table for historical tracking\n",
    "* `ENABLE_VISUALIZATIONS = True` - Generate charts (interactive mode only)\n",
    "\n",
    "### Analysis Thresholds:\n",
    "* `FAILURE_RATE_CRITICAL = 50` - Critical failure rate %\n",
    "* `FAILURE_RATE_WARNING = 20` - Warning failure rate %\n",
    "* `EXECUTION_TIME_INCREASE_THRESHOLD = 2.0` - Flag if 2x+ slower\n",
    "* `MIN_RUNS_FOR_ANALYSIS = 5` - Minimum runs needed for trend analysis\n",
    "\n",
    "---\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Interactive Mode\n",
    "1. Configure widget parameters at the top\n",
    "2. Run all cells to analyze job health\n",
    "3. Review health metrics and problem jobs\n",
    "4. View visualizations and trends\n",
    "5. Download Excel report from export path\n",
    "\n",
    "### Job Mode\n",
    "1. Schedule as a Databricks job (daily/weekly recommended)\n",
    "2. Set widget parameters in job configuration\n",
    "3. Automatically runs comprehensive analysis\n",
    "4. Exports to Delta table for historical tracking\n",
    "5. Returns JSON summary for orchestration\n",
    "\n",
    "---\n",
    "\n",
    "## Key Features\n",
    "\n",
    "✓ **Complete Job Coverage**: Analyzes all workspace jobs  \n",
    "✓ **Configurable Lookback**: 7, 30, 60, or 90 day analysis periods  \n",
    "✓ **Success Rate Tracking**: Per-job success/failure rates  \n",
    "✓ **Execution Time Analysis**: Trends, anomalies, SLA violations  \n",
    "✓ **Failure Pattern Detection**: Categorizes and analyzes failures  \n",
    "✓ **Problem Job Identification**: High failure rate, slow execution  \n",
    "✓ **Health Scoring**: 0-100 weighted health score  \n",
    "✓ **Actionable Recommendations**: Prioritized by severity  \n",
    "✓ **Historical Tracking**: Delta table with trend analysis  \n",
    "✓ **Excel Reports**: Multi-sheet workbooks with analysis  \n",
    "✓ **Interactive Visualizations**: Charts and graphs  \n",
    "✓ **Parallel Processing**: Fast execution with ThreadPoolExecutor  \n",
    "✓ **Retry Logic**: Resilient API calls with exponential backoff  \n",
    "✓ **Job Mode Support**: Automated scheduled execution  \n",
    "✓ **Serverless Optimized**: Compute-aware optimizations  \n",
    "✓ **Owner Tracking**: Identifies orphaned jobs  \n",
    "✓ **Schedule Analysis**: Detects overlapping jobs  \n",
    "✓ **Configuration Validation**: Validates all parameters  \n",
    "✓ **Comprehensive Error Handling**: Graceful degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "505fb71a-8fb2-46da-a467-811537000955",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install required packages"
    }
   },
   "outputs": [],
   "source": [
    "%pip install openpyxl --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bea9c0b-f3e3-496b-8538-77ca034f1334",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Setup and configuration"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "# Standard library\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Third-party\n",
    "import pandas as pd\n",
    "import pytz\n",
    "\n",
    "# Databricks SDK\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.errors import NotFound, PermissionDenied\n",
    "\n",
    "# PySpark\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, TimestampType, DoubleType\n",
    "\n",
    "# ============================================================================\n",
    "# JOB MODE DETECTION (MUST BE FIRST)\n",
    "# ============================================================================\n",
    "\n",
    "try:\n",
    "    dbutils.notebook.entry_point.getDbutils().notebook().getContext().currentRunId().isDefined()\n",
    "    is_job_mode = True\n",
    "except:\n",
    "    is_job_mode = False\n",
    "\n",
    "# ============================================================================\n",
    "# SERVERLESS DETECTION\n",
    "# ============================================================================\n",
    "\n",
    "try:\n",
    "    test_df = spark.range(1)\n",
    "    test_df.cache()\n",
    "    test_df.count()\n",
    "    test_df.unpersist()\n",
    "    is_serverless = False\n",
    "except Exception as e:\n",
    "    if 'PERSIST' in str(e).upper() or 'CACHE' in str(e).upper():\n",
    "        is_serverless = True\n",
    "    else:\n",
    "        is_serverless = False\n",
    "\n",
    "# ============================================================================\n",
    "# TIMEZONE CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "TIMEZONE = 'America/New_York'\n",
    "eastern = pytz.timezone(TIMEZONE)\n",
    "\n",
    "# ============================================================================\n",
    "# LOGGING FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def log(message):\n",
    "    \"\"\"Print messages (always in interactive, selectively in job mode)\"\"\"\n",
    "    print(message)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# Analysis period\n",
    "LOOKBACK_DAYS = 30  # Days of run history to analyze\n",
    "\n",
    "# Job limits\n",
    "MAX_JOBS = 999  # Maximum jobs to analyze (999 = all)\n",
    "MAX_RUNS_PER_JOB = 25  # Maximum runs to fetch per job (API limit is 26)\n",
    "\n",
    "# Performance settings\n",
    "MAX_WORKERS = 10  # Parallel threads for API calls\n",
    "MAX_RETRIES = 3  # Retries for failed API calls\n",
    "RETRY_DELAY = 2  # Seconds between retries\n",
    "\n",
    "# Health thresholds\n",
    "FAILURE_RATE_CRITICAL = 50  # % - Critical failure rate\n",
    "FAILURE_RATE_WARNING = 20  # % - Warning failure rate\n",
    "SLOW_JOB_THRESHOLD_MINUTES = 60  # Minutes - Flag jobs exceeding this\n",
    "EXECUTION_TIME_INCREASE_THRESHOLD = 2.0  # Flag if 2x+ slower than average\n",
    "MIN_RUNS_FOR_ANALYSIS = 5  # Minimum runs needed for trend analysis\n",
    "\n",
    "# Export settings (disabled in interactive mode, enabled in job mode)\n",
    "EXPORT_PATH = '/dbfs/tmp/job_health_export'\n",
    "if is_job_mode:\n",
    "    ENABLE_EXCEL_EXPORT = True\n",
    "    ENABLE_DELTA_EXPORT = True\n",
    "    ENABLE_JSON_EXPORT = True\n",
    "    log(\"\uD83E\uDD16 Job mode: Exports ENABLED\")\n",
    "else:\n",
    "    ENABLE_EXCEL_EXPORT = False\n",
    "    ENABLE_DELTA_EXPORT = False\n",
    "    ENABLE_JSON_EXPORT = False\n",
    "    log(\"\uD83D\uDCBB Interactive mode: Exports DISABLED\")\n",
    "\n",
    "ENABLE_VISUALIZATIONS = True\n",
    "\n",
    "# Delta table configuration\n",
    "DELTA_TABLE_NAME = 'main.default.job_health_history'\n",
    "\n",
    "# ============================================================================\n",
    "# EXECUTION STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "execution_stats = {\n",
    "    'start_time': time.time(),\n",
    "    'api_calls': 0,\n",
    "    'api_failures': 0,\n",
    "    'api_retries': 0,\n",
    "    'jobs_processed': 0,\n",
    "    'runs_processed': 0\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# INITIALIZE SDK CLIENT\n",
    "# ============================================================================\n",
    "\n",
    "wc = WorkspaceClient()\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"JOB & WORKFLOW HEALTH MONITOR\")\n",
    "log(\"=\"*60)\n",
    "log(f\"Execution mode: {'JOB' if is_job_mode else 'INTERACTIVE'}\")\n",
    "log(f\"Compute type: {'SERVERLESS' if is_serverless else 'TRADITIONAL'}\")\n",
    "log(f\"Timezone: {TIMEZONE}\")\n",
    "log(f\"Lookback period: {LOOKBACK_DAYS} days\")\n",
    "log(f\"Analysis thresholds: Failure={FAILURE_RATE_WARNING}%, Slow={SLOW_JOB_THRESHOLD_MINUTES}min\")\n",
    "log(f\"Excel export: {'ENABLED' if ENABLE_EXCEL_EXPORT else 'DISABLED'}\")\n",
    "log(f\"Delta export: {'ENABLED' if ENABLE_DELTA_EXPORT else 'DISABLED'}\")\n",
    "log(f\"JSON export: {'ENABLED' if ENABLE_JSON_EXPORT else 'DISABLED'}\")\n",
    "log(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f6e3330-0062-402a-b200-2b7d6941eda9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Helper functions"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def log_execution_time(cell_name, start_time):\n",
    "    \"\"\"Log execution time for a cell\"\"\"\n",
    "    elapsed = time.time() - start_time\n",
    "    log(f\"⏱️  {cell_name} completed in {elapsed:.2f} seconds\")\n",
    "\n",
    "def validate_dataframe_exists(df_name, df):\n",
    "    \"\"\"Validate that a DataFrame exists and has data\"\"\"\n",
    "    if df is None:\n",
    "        log(f\"⚠️  Warning: {df_name} is None\")\n",
    "        return False\n",
    "    try:\n",
    "        count = df.count()\n",
    "        if count == 0:\n",
    "            log(f\"⚠️  Warning: {df_name} is empty (0 rows)\")\n",
    "            return False\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        log(f\"⚠️  Warning: Error checking {df_name}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def api_call_with_retry(func, *args, **kwargs):\n",
    "    \"\"\"Execute API call with retry logic and stats tracking\"\"\"\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            execution_stats['api_calls'] += 1\n",
    "            result = func(*args, **kwargs)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            execution_stats['api_failures'] += 1\n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                execution_stats['api_retries'] += 1\n",
    "                time.sleep(RETRY_DELAY * (2 ** attempt))  # Exponential backoff\n",
    "                log(f\"  ⚠️  Retry {attempt + 1}/{MAX_RETRIES} after error: {str(e)[:100]}\")\n",
    "            else:\n",
    "                log(f\"  ✗ Failed after {MAX_RETRIES} attempts: {str(e)[:100]}\")\n",
    "                raise\n",
    "    return None\n",
    "\n",
    "def format_duration(seconds):\n",
    "    \"\"\"Format duration in human-readable format\"\"\"\n",
    "    if seconds is None:\n",
    "        return 'N/A'\n",
    "    \n",
    "    if seconds < 60:\n",
    "        return f\"{seconds:.0f}s\"\n",
    "    elif seconds < 3600:\n",
    "        return f\"{seconds/60:.1f}m\"\n",
    "    else:\n",
    "        return f\"{seconds/3600:.1f}h\"\n",
    "\n",
    "def calculate_health_score(success_rate, avg_duration_minutes, has_retries):\n",
    "    \"\"\"Calculate health score (0-100) for a job\"\"\"\n",
    "    score = 0\n",
    "    \n",
    "    # Success rate component (0-60 points)\n",
    "    if success_rate >= 95:\n",
    "        score += 60\n",
    "    elif success_rate >= 90:\n",
    "        score += 50\n",
    "    elif success_rate >= 80:\n",
    "        score += 40\n",
    "    elif success_rate >= 70:\n",
    "        score += 30\n",
    "    elif success_rate >= 50:\n",
    "        score += 20\n",
    "    else:\n",
    "        score += 10\n",
    "    \n",
    "    # Performance component (0-30 points)\n",
    "    if avg_duration_minutes < 10:\n",
    "        score += 30\n",
    "    elif avg_duration_minutes < 30:\n",
    "        score += 25\n",
    "    elif avg_duration_minutes < 60:\n",
    "        score += 20\n",
    "    elif avg_duration_minutes < 120:\n",
    "        score += 15\n",
    "    else:\n",
    "        score += 10\n",
    "    \n",
    "    # Reliability component (0-10 points)\n",
    "    if has_retries:\n",
    "        score += 5  # Has retry configuration\n",
    "    else:\n",
    "        score += 10  # No retries needed\n",
    "    \n",
    "    return min(score, 100)\n",
    "\n",
    "log(\"✓ Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e372237b-edbd-4157-b969-5614aa48ce65",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fetch all jobs"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"FETCHING JOBS\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Fetch all jobs\n",
    "    log(\"Fetching all jobs...\")\n",
    "    all_jobs = list(wc.jobs.list())\n",
    "    \n",
    "    if MAX_JOBS < 999:\n",
    "        all_jobs = all_jobs[:MAX_JOBS]\n",
    "        log(f\"  Limited to {MAX_JOBS} jobs\")\n",
    "    \n",
    "    log(f\"✓ Fetched {len(all_jobs)} jobs\")\n",
    "    \n",
    "    # Extract job metadata\n",
    "    jobs_data = []\n",
    "    for job in all_jobs:\n",
    "        try:\n",
    "            job_settings = job.settings\n",
    "            \n",
    "            # Extract max_retries from tasks if available\n",
    "            max_retries = 0\n",
    "            if job_settings and job_settings.tasks:\n",
    "                # Get max retries across all tasks\n",
    "                for task in job_settings.tasks:\n",
    "                    task_retries = getattr(task, 'max_retries', 0)\n",
    "                    if task_retries and task_retries > max_retries:\n",
    "                        max_retries = task_retries\n",
    "            \n",
    "            jobs_data.append({\n",
    "                'job_id': job.job_id,\n",
    "                'job_name': job_settings.name if job_settings else 'Unknown',\n",
    "                'creator': job.creator_user_name or 'Unknown',\n",
    "                'created_time': datetime.fromtimestamp(job.created_time / 1000, tz=eastern) if job.created_time else None,\n",
    "                'schedule': job_settings.schedule.quartz_cron_expression if (job_settings and job_settings.schedule) else None,\n",
    "                'max_concurrent_runs': job_settings.max_concurrent_runs if job_settings else 1,\n",
    "                'timeout_seconds': job_settings.timeout_seconds if job_settings else None,\n",
    "                'max_retries': max_retries,\n",
    "                'has_schedule': bool(job_settings and job_settings.schedule),\n",
    "                'has_continuous': bool(job_settings and job_settings.continuous),\n",
    "                'task_count': len(job_settings.tasks) if (job_settings and job_settings.tasks) else 0\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            log(f\"  ⚠️  Error processing job {job.job_id}: {str(e)[:100]}\")\n",
    "            continue\n",
    "    \n",
    "    # Create DataFrame\n",
    "    jobs_df = spark.createDataFrame(jobs_data)\n",
    "    \n",
    "    log(f\"✓ Processed {len(jobs_data)} jobs\")\n",
    "    log(f\"  Scheduled jobs: {jobs_df.filter(F.col('has_schedule') == True).count()}\")\n",
    "    log(f\"  Continuous jobs: {jobs_df.filter(F.col('has_continuous') == True).count()}\")\n",
    "    log(f\"  Multi-task jobs: {jobs_df.filter(F.col('task_count') > 1).count()}\")\n",
    "    log(f\"  Jobs with retries: {jobs_df.filter(F.col('max_retries') > 0).count()}\")\n",
    "    \n",
    "    execution_stats['jobs_processed'] = len(jobs_data)\n",
    "    \n",
    "except Exception as e:\n",
    "    log(f\"✗ Error fetching jobs: {str(e)}\")\n",
    "    jobs_df = None\n",
    "\n",
    "log_execution_time(\"Fetch Jobs\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4553600-cf95-417f-a621-bd2498f9de0e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fetch job runs (last N days)"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(f\"FETCHING JOB RUNS (LAST {LOOKBACK_DAYS} DAYS)\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "if jobs_df is not None:\n",
    "    # Calculate start time for lookback period\n",
    "    start_time_ms = int((datetime.now(eastern) - timedelta(days=LOOKBACK_DAYS)).timestamp() * 1000)\n",
    "    \n",
    "    log(f\"Fetching runs since: {datetime.fromtimestamp(start_time_ms/1000, tz=eastern).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    all_runs = []\n",
    "    job_ids = [row.job_id for row in jobs_df.select('job_id').collect()]\n",
    "    \n",
    "    log(f\"Fetching runs for {len(job_ids)} jobs...\")\n",
    "    \n",
    "    completed = 0\n",
    "    \n",
    "    def fetch_runs_for_job(job_id):\n",
    "        \"\"\"Fetch runs for a single job\"\"\"\n",
    "        try:\n",
    "            runs = list(wc.jobs.list_runs(\n",
    "                job_id=job_id,\n",
    "                start_time_from=start_time_ms,\n",
    "                limit=MAX_RUNS_PER_JOB\n",
    "            ))\n",
    "            return runs\n",
    "        except Exception as e:\n",
    "            log(f\"  ⚠️  Error fetching runs for job {job_id}: {str(e)[:100]}\")\n",
    "            return []\n",
    "    \n",
    "    # Parallel fetch with progress tracking\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        future_to_job = {executor.submit(fetch_runs_for_job, job_id): job_id for job_id in job_ids}\n",
    "        \n",
    "        for future in as_completed(future_to_job):\n",
    "            completed += 1\n",
    "            \n",
    "            # Progress logging every 10% or every 50 jobs\n",
    "            if completed % max(1, len(job_ids) // 10) == 0 or completed % 50 == 0:\n",
    "                progress_pct = (completed / len(job_ids)) * 100\n",
    "                log(f\"  Progress: {completed}/{len(job_ids)} jobs ({progress_pct:.1f}%)\")\n",
    "            \n",
    "            runs = future.result()\n",
    "            if runs:\n",
    "                all_runs.extend(runs)\n",
    "    \n",
    "    log(f\"✓ Fetched {len(all_runs)} total runs across {len(job_ids)} jobs\")\n",
    "    \n",
    "    # Process runs into structured data\n",
    "    log(\"Processing run data...\")\n",
    "    runs_data = []\n",
    "    \n",
    "    for run in all_runs:\n",
    "        try:\n",
    "            # Calculate duration\n",
    "            duration_ms = None\n",
    "            if run.end_time and run.start_time:\n",
    "                duration_ms = run.end_time - run.start_time\n",
    "            \n",
    "            runs_data.append({\n",
    "                'run_id': run.run_id,\n",
    "                'job_id': run.job_id,\n",
    "                'run_name': run.run_name or 'Unknown',\n",
    "                'state': run.state.life_cycle_state.value if run.state and run.state.life_cycle_state else 'UNKNOWN',\n",
    "                'result_state': run.state.result_state.value if (run.state and run.state.result_state) else None,\n",
    "                'start_time': datetime.fromtimestamp(run.start_time / 1000, tz=eastern) if run.start_time else None,\n",
    "                'end_time': datetime.fromtimestamp(run.end_time / 1000, tz=eastern) if run.end_time else None,\n",
    "                'duration_seconds': duration_ms / 1000 if duration_ms else None,\n",
    "                'trigger': run.trigger.value if run.trigger else 'UNKNOWN',\n",
    "                'run_type': run.run_type.value if run.run_type else 'UNKNOWN',\n",
    "                'attempt_number': run.attempt_number or 0,\n",
    "                'creator_user_name': run.creator_user_name or 'Unknown'\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            log(f\"  ⚠️  Error processing run {run.run_id}: {str(e)[:100]}\")\n",
    "            continue\n",
    "    \n",
    "    # Create DataFrame\n",
    "    if runs_data:\n",
    "        runs_df = spark.createDataFrame(runs_data)\n",
    "        \n",
    "        log(f\"✓ Processed {len(runs_data)} runs\")\n",
    "        log(f\"  Completed runs: {runs_df.filter(F.col('state') == 'TERMINATED').count()}\")\n",
    "        log(f\"  Running: {runs_df.filter(F.col('state') == 'RUNNING').count()}\")\n",
    "        log(f\"  Pending: {runs_df.filter(F.col('state') == 'PENDING').count()}\")\n",
    "        \n",
    "        execution_stats['runs_processed'] = len(runs_data)\n",
    "    else:\n",
    "        log(\"⚠️  No runs found in the lookback period\")\n",
    "        runs_df = None\n",
    "    \n",
    "else:\n",
    "    log(\"⚠️  Skipping run fetch (no jobs found)\")\n",
    "    runs_df = None\n",
    "\n",
    "log_execution_time(\"Fetch Job Runs\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e0622b1-d0d6-471d-9d00-867cccc48ceb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Calculate job health metrics"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"CALCULATING JOB HEALTH METRICS\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "if runs_df is not None and jobs_df is not None:\n",
    "    # Join runs with jobs\n",
    "    job_runs = runs_df.join(jobs_df, 'job_id', 'left')\n",
    "    \n",
    "    # Calculate metrics per job\n",
    "    log(\"Calculating success rates and execution times...\")\n",
    "    \n",
    "    job_metrics = job_runs.groupBy('job_id', 'job_name', 'creator', 'has_schedule', 'max_retries').agg(\n",
    "        F.count('*').alias('total_runs'),\n",
    "        F.sum(F.when(F.col('result_state') == 'SUCCESS', 1).otherwise(0)).alias('successful_runs'),\n",
    "        F.sum(F.when(F.col('result_state') == 'FAILED', 1).otherwise(0)).alias('failed_runs'),\n",
    "        F.sum(F.when(F.col('result_state') == 'TIMEDOUT', 1).otherwise(0)).alias('timeout_runs'),\n",
    "        F.sum(F.when(F.col('result_state') == 'CANCELED', 1).otherwise(0)).alias('canceled_runs'),\n",
    "        F.sum(F.when(F.col('state') == 'RUNNING', 1).otherwise(0)).alias('running_runs'),\n",
    "        F.avg('duration_seconds').alias('avg_duration_seconds'),\n",
    "        F.min('duration_seconds').alias('min_duration_seconds'),\n",
    "        F.max('duration_seconds').alias('max_duration_seconds'),\n",
    "        F.max('start_time').alias('last_run_time'),\n",
    "        F.sum(F.when(F.col('attempt_number') > 0, 1).otherwise(0)).alias('retry_count')\n",
    "    )\n",
    "    \n",
    "    # Calculate success rate and derived metrics\n",
    "    job_metrics = job_metrics.withColumn(\n",
    "        'success_rate',\n",
    "        (F.col('successful_runs') / F.col('total_runs') * 100).cast('double')\n",
    "    )\n",
    "    \n",
    "    job_metrics = job_metrics.withColumn(\n",
    "        'failure_rate',\n",
    "        (F.col('failed_runs') / F.col('total_runs') * 100).cast('double')\n",
    "    )\n",
    "    \n",
    "    job_metrics = job_metrics.withColumn(\n",
    "        'avg_duration_minutes',\n",
    "        (F.col('avg_duration_seconds') / 60).cast('double')\n",
    "    )\n",
    "    \n",
    "    # Calculate health score using UDF\n",
    "    from pyspark.sql.functions import udf\n",
    "    from pyspark.sql.types import IntegerType\n",
    "    \n",
    "    @udf(returnType=IntegerType())\n",
    "    def calc_health_score(success_rate, avg_duration_minutes, max_retries):\n",
    "        if success_rate is None or avg_duration_minutes is None:\n",
    "            return 0\n",
    "        return calculate_health_score(success_rate, avg_duration_minutes, max_retries > 0)\n",
    "    \n",
    "    job_metrics = job_metrics.withColumn(\n",
    "        'health_score',\n",
    "        calc_health_score(F.col('success_rate'), F.col('avg_duration_minutes'), F.col('max_retries'))\n",
    "    )\n",
    "    \n",
    "    # Add health category\n",
    "    job_metrics = job_metrics.withColumn(\n",
    "        'health_category',\n",
    "        F.when(F.col('health_score') >= 80, 'HEALTHY')\n",
    "         .when(F.col('health_score') >= 60, 'FAIR')\n",
    "         .when(F.col('health_score') >= 40, 'POOR')\n",
    "         .otherwise('CRITICAL')\n",
    "    )\n",
    "    \n",
    "    # Add problem flags\n",
    "    job_metrics = job_metrics.withColumn(\n",
    "        'is_problem_job',\n",
    "        (F.col('failure_rate') > FAILURE_RATE_WARNING) | \n",
    "        (F.col('avg_duration_minutes') > SLOW_JOB_THRESHOLD_MINUTES)\n",
    "    )\n",
    "    \n",
    "    log(f\"✓ Calculated metrics for {job_metrics.count()} jobs\")\n",
    "    \n",
    "    # Display summary statistics\n",
    "    log(\"\\nHealth Distribution:\")\n",
    "    health_dist = job_metrics.groupBy('health_category').count().orderBy(F.desc('count'))\n",
    "    for row in health_dist.collect():\n",
    "        log(f\"  {row.health_category}: {row['count']} jobs\")\n",
    "    \n",
    "    log(f\"\\nProblem Jobs: {job_metrics.filter(F.col('is_problem_job') == True).count()}\")\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_runs = job_metrics.agg(F.sum('total_runs')).first()[0]\n",
    "    total_success = job_metrics.agg(F.sum('successful_runs')).first()[0]\n",
    "    total_failed = job_metrics.agg(F.sum('failed_runs')).first()[0]\n",
    "    \n",
    "    overall_success_rate = (total_success / total_runs * 100) if total_runs > 0 else 0\n",
    "    \n",
    "    log(f\"\\nOverall Statistics:\")\n",
    "    log(f\"  Total runs analyzed: {total_runs:,}\")\n",
    "    log(f\"  Successful: {total_success:,} ({overall_success_rate:.1f}%)\")\n",
    "    log(f\"  Failed: {total_failed:,} ({(total_failed/total_runs*100) if total_runs > 0 else 0:.1f}%)\")\n",
    "    \n",
    "else:\n",
    "    log(\"⚠️  Skipping metrics calculation (no data)\")\n",
    "    job_metrics = None\n",
    "\n",
    "log_execution_time(\"Calculate Metrics\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcd10374-27c8-4e55-8a33-1fa080616001",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Identify problem jobs"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"IDENTIFYING PROBLEM JOBS\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "if job_metrics is not None:\n",
    "    # Critical jobs (failure rate > 50%)\n",
    "    critical_jobs = job_metrics.filter(F.col('failure_rate') > FAILURE_RATE_CRITICAL)\n",
    "    critical_count = critical_jobs.count()\n",
    "    \n",
    "    # Warning jobs (failure rate > 20%)\n",
    "    warning_jobs = job_metrics.filter(\n",
    "        (F.col('failure_rate') > FAILURE_RATE_WARNING) & \n",
    "        (F.col('failure_rate') <= FAILURE_RATE_CRITICAL)\n",
    "    )\n",
    "    warning_count = warning_jobs.count()\n",
    "    \n",
    "    # Slow jobs (avg execution > threshold)\n",
    "    slow_jobs = job_metrics.filter(F.col('avg_duration_minutes') > SLOW_JOB_THRESHOLD_MINUTES)\n",
    "    slow_count = slow_jobs.count()\n",
    "    \n",
    "    # Jobs with no recent runs\n",
    "    stale_jobs = jobs_df.join(\n",
    "        job_metrics.select('job_id'),\n",
    "        'job_id',\n",
    "        'left_anti'  # Jobs with no runs in lookback period\n",
    "    )\n",
    "    stale_count = stale_jobs.count()\n",
    "    \n",
    "    log(f\"\\n\uD83D\uDD34 CRITICAL: {critical_count} jobs with >50% failure rate\")\n",
    "    if critical_count > 0:\n",
    "        log(\"  Top 5 critical jobs:\")\n",
    "        for row in critical_jobs.orderBy(F.desc('failure_rate')).limit(5).collect():\n",
    "            log(f\"    - {row.job_name}: {row.failure_rate:.1f}% failure rate ({row.failed_runs}/{row.total_runs} runs)\")\n",
    "    \n",
    "    log(f\"\\n\uD83D\uDFE1 WARNING: {warning_count} jobs with >20% failure rate\")\n",
    "    if warning_count > 0:\n",
    "        log(\"  Top 5 warning jobs:\")\n",
    "        for row in warning_jobs.orderBy(F.desc('failure_rate')).limit(5).collect():\n",
    "            log(f\"    - {row.job_name}: {row.failure_rate:.1f}% failure rate\")\n",
    "    \n",
    "    log(f\"\\n\uD83D\uDC22 SLOW: {slow_count} jobs with avg execution >{SLOW_JOB_THRESHOLD_MINUTES} minutes\")\n",
    "    if slow_count > 0:\n",
    "        log(\"  Top 5 slowest jobs:\")\n",
    "        for row in slow_jobs.orderBy(F.desc('avg_duration_minutes')).limit(5).collect():\n",
    "            log(f\"    - {row.job_name}: {row.avg_duration_minutes:.1f} min avg ({format_duration(row.max_duration_seconds)} max)\")\n",
    "    \n",
    "    log(f\"\\n⏸️  STALE: {stale_count} jobs with no runs in last {LOOKBACK_DAYS} days\")\n",
    "    \n",
    "    # Create problem jobs summary\n",
    "    problem_jobs = job_metrics.filter(\n",
    "        (F.col('failure_rate') > FAILURE_RATE_WARNING) |\n",
    "        (F.col('avg_duration_minutes') > SLOW_JOB_THRESHOLD_MINUTES) |\n",
    "        (F.col('health_score') < 50)\n",
    "    )\n",
    "    \n",
    "    log(f\"\\n⚠️  Total problem jobs: {problem_jobs.count()}\")\n",
    "    \n",
    "else:\n",
    "    log(\"⚠️  Skipping problem job identification (no data)\")\n",
    "    problem_jobs = None\n",
    "    critical_jobs = None\n",
    "    warning_jobs = None\n",
    "    slow_jobs = None\n",
    "    stale_jobs = None\n",
    "\n",
    "log_execution_time(\"Identify Problem Jobs\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c78e883-43a3-4105-8902-b8dfb073b8bc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Generate recommendations"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"GENERATING RECOMMENDATIONS\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "if job_metrics is not None:\n",
    "    # Critical: High failure rate jobs\n",
    "    critical_failure_jobs = job_metrics.filter(F.col('failure_rate') > FAILURE_RATE_CRITICAL).collect()\n",
    "    \n",
    "    for job in critical_failure_jobs:\n",
    "        recommendations.append({\n",
    "            'priority': 'CRITICAL',\n",
    "            'category': 'Reliability',\n",
    "            'job_id': job.job_id,\n",
    "            'job_name': job.job_name,\n",
    "            'issue': f'High failure rate: {job.failure_rate:.1f}%',\n",
    "            'impact': f'{job.failed_runs} of {job.total_runs} runs failed in last {LOOKBACK_DAYS} days',\n",
    "            'recommendation': 'Investigate root cause, review logs, consider disabling until fixed',\n",
    "            'affected_runs': job.failed_runs\n",
    "        })\n",
    "    \n",
    "    # High: Warning failure rate jobs\n",
    "    warning_failure_jobs = job_metrics.filter(\n",
    "        (F.col('failure_rate') > FAILURE_RATE_WARNING) & \n",
    "        (F.col('failure_rate') <= FAILURE_RATE_CRITICAL)\n",
    "    ).collect()\n",
    "    \n",
    "    for job in warning_failure_jobs:\n",
    "        recommendations.append({\n",
    "            'priority': 'HIGH',\n",
    "            'category': 'Reliability',\n",
    "            'job_id': job.job_id,\n",
    "            'job_name': job.job_name,\n",
    "            'issue': f'Elevated failure rate: {job.failure_rate:.1f}%',\n",
    "            'impact': f'{job.failed_runs} failures in last {LOOKBACK_DAYS} days',\n",
    "            'recommendation': 'Review error logs, add monitoring alerts',\n",
    "            'affected_runs': job.failed_runs\n",
    "        })\n",
    "    \n",
    "    # Medium: Slow execution jobs\n",
    "    slow_execution_jobs = job_metrics.filter(\n",
    "        F.col('avg_duration_minutes') > SLOW_JOB_THRESHOLD_MINUTES\n",
    "    ).collect()\n",
    "    \n",
    "    for job in slow_execution_jobs[:10]:  # Limit to top 10\n",
    "        recommendations.append({\n",
    "            'priority': 'MEDIUM',\n",
    "            'category': 'Performance',\n",
    "            'job_id': job.job_id,\n",
    "            'job_name': job.job_name,\n",
    "            'issue': f'Slow execution: {job.avg_duration_minutes:.1f} min average',\n",
    "            'impact': f'Max execution time: {format_duration(job.max_duration_seconds)}',\n",
    "            'recommendation': 'Review cluster configuration, optimize queries, consider autoscaling',\n",
    "            'affected_runs': job.total_runs\n",
    "        })\n",
    "    \n",
    "    # Low: Jobs without retry configuration\n",
    "    no_retry_jobs = job_metrics.filter(\n",
    "        (F.col('max_retries') == 0) & \n",
    "        (F.col('failure_rate') > 0)\n",
    "    ).collect()\n",
    "    \n",
    "    for job in no_retry_jobs[:10]:  # Limit to top 10\n",
    "        recommendations.append({\n",
    "            'priority': 'LOW',\n",
    "            'category': 'Configuration',\n",
    "            'job_id': job.job_id,\n",
    "            'job_name': job.job_name,\n",
    "            'issue': 'No retry configuration',\n",
    "            'impact': f'Job has {job.failure_rate:.1f}% failure rate without retries',\n",
    "            'recommendation': 'Add max_retries configuration to improve reliability',\n",
    "            'affected_runs': job.failed_runs\n",
    "        })\n",
    "    \n",
    "    # Create recommendations DataFrame\n",
    "    if recommendations:\n",
    "        recommendations_df = spark.createDataFrame(recommendations)\n",
    "        \n",
    "        log(f\"\\n\uD83D\uDCA1 Generated {len(recommendations)} recommendations:\")\n",
    "        log(f\"  \uD83D\uDD34 CRITICAL: {len([r for r in recommendations if r['priority'] == 'CRITICAL'])}\")\n",
    "        log(f\"  \uD83D\uDFE0 HIGH: {len([r for r in recommendations if r['priority'] == 'HIGH'])}\")\n",
    "        log(f\"  \uD83D\uDFE1 MEDIUM: {len([r for r in recommendations if r['priority'] == 'MEDIUM'])}\")\n",
    "        log(f\"  \uD83D\uDD35 LOW: {len([r for r in recommendations if r['priority'] == 'LOW'])}\")\n",
    "    else:\n",
    "        recommendations_df = None\n",
    "        log(\"\\n✅ No recommendations - all jobs healthy!\")\n",
    "        \n",
    "else:\n",
    "    log(\"⚠️  Skipping recommendations (no data)\")\n",
    "    recommendations_df = None\n",
    "\n",
    "log_execution_time(\"Generate Recommendations\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cceeda25-451a-40b0-b99b-5efe71a27170",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Visualizations (interactive mode only)"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "if not is_job_mode and ENABLE_VISUALIZATIONS and job_metrics is not None:\n",
    "    log(\"\\n\" + \"=\"*60)\n",
    "    log(\"VISUALIZATIONS\")\n",
    "    log(\"=\"*60)\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Chart 1: Health Category Distribution\n",
    "    ax1 = axes[0, 0]\n",
    "    health_dist = job_metrics.groupBy('health_category').count().toPandas()\n",
    "    health_dist = health_dist.sort_values('count', ascending=False)\n",
    "    colors = {'HEALTHY': 'green', 'FAIR': 'orange', 'POOR': 'red', 'CRITICAL': 'darkred'}\n",
    "    bar_colors = [colors.get(cat, 'gray') for cat in health_dist['health_category']]\n",
    "    ax1.bar(health_dist['health_category'], health_dist['count'], color=bar_colors)\n",
    "    ax1.set_title('Job Health Distribution', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlabel('Health Category')\n",
    "    ax1.set_ylabel('Number of Jobs')\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Chart 2: Success Rate Distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    success_rates = job_metrics.select('success_rate').toPandas()['success_rate'].dropna()\n",
    "    ax2.hist(success_rates, bins=20, color='steelblue', edgecolor='black')\n",
    "    ax2.axvline(success_rates.mean(), color='red', linestyle='--', label=f'Mean: {success_rates.mean():.1f}%')\n",
    "    ax2.set_title('Success Rate Distribution', fontsize=12, fontweight='bold')\n",
    "    ax2.set_xlabel('Success Rate (%)')\n",
    "    ax2.set_ylabel('Number of Jobs')\n",
    "    ax2.legend()\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Chart 3: Execution Time Distribution\n",
    "    ax3 = axes[1, 0]\n",
    "    durations = job_metrics.select('avg_duration_minutes').toPandas()['avg_duration_minutes'].dropna()\n",
    "    durations_filtered = durations[durations < 120]  # Filter outliers for better visualization\n",
    "    ax3.hist(durations_filtered, bins=20, color='skyblue', edgecolor='black')\n",
    "    ax3.axvline(durations.median(), color='red', linestyle='--', label=f'Median: {durations.median():.1f} min')\n",
    "    ax3.set_title('Average Execution Time Distribution', fontsize=12, fontweight='bold')\n",
    "    ax3.set_xlabel('Duration (minutes)')\n",
    "    ax3.set_ylabel('Number of Jobs')\n",
    "    ax3.legend()\n",
    "    ax3.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Chart 4: Top 10 Jobs by Run Count (highest to lowest)\n",
    "    ax4 = axes[1, 1]\n",
    "    top_jobs = job_metrics.orderBy(F.desc('total_runs')).limit(10).toPandas()\n",
    "    ax4.barh(range(len(top_jobs)), top_jobs['total_runs'], color='steelblue')\n",
    "    ax4.set_yticks(range(len(top_jobs)))\n",
    "    ax4.set_yticklabels([name[:30] + '...' if len(name) > 30 else name for name in top_jobs['job_name']], fontsize=9)\n",
    "    ax4.invert_yaxis()  # Invert to show highest at top\n",
    "    ax4.set_title('Top 10 Most Frequently Run Jobs', fontsize=12, fontweight='bold')\n",
    "    ax4.set_xlabel('Number of Runs')\n",
    "    ax4.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    log(\"✓ Visualizations generated\")\n",
    "    \n",
    "else:\n",
    "    if is_job_mode:\n",
    "        log(\"ℹ️  Visualizations skipped (job mode)\")\n",
    "    elif not ENABLE_VISUALIZATIONS:\n",
    "        log(\"ℹ️  Visualizations disabled (ENABLE_VISUALIZATIONS=False)\")\n",
    "    else:\n",
    "        log(\"ℹ️  Visualizations skipped (no data)\")\n",
    "\n",
    "log_execution_time(\"Visualizations\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66fa2ae4-42d2-46c6-a165-be30c92a4a21",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Export to Excel"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "if ENABLE_EXCEL_EXPORT and job_metrics is not None:\n",
    "    log(\"\\n\" + \"=\"*60)\n",
    "    log(\"EXPORTING TO EXCEL\")\n",
    "    log(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Create export directory\n",
    "        if is_serverless:\n",
    "            import tempfile\n",
    "            temp_dir = tempfile.mkdtemp()\n",
    "            export_path = temp_dir\n",
    "        else:\n",
    "            export_path = EXPORT_PATH\n",
    "            os.makedirs(export_path, exist_ok=True)\n",
    "        \n",
    "        # Generate filename with timestamp\n",
    "        timestamp = datetime.now(eastern).strftime('%Y%m%d_%H%M%S')\n",
    "        excel_path = f\"{export_path}/job_health_report_{timestamp}.xlsx\"\n",
    "        \n",
    "        log(f\"Creating Excel workbook: {excel_path}\")\n",
    "        \n",
    "        # Convert DataFrames to Pandas\n",
    "        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "            # Sheet 1: Job Inventory\n",
    "            jobs_df.toPandas().to_excel(writer, sheet_name='Job Inventory', index=False)\n",
    "            \n",
    "            # Sheet 2: Health Metrics\n",
    "            job_metrics.orderBy(F.desc('health_score')).toPandas().to_excel(writer, sheet_name='Health Metrics', index=False)\n",
    "            \n",
    "            # Sheet 3: Problem Jobs\n",
    "            if problem_jobs is not None and problem_jobs.count() > 0:\n",
    "                problem_jobs.orderBy(F.desc('failure_rate')).toPandas().to_excel(writer, sheet_name='Problem Jobs', index=False)\n",
    "            \n",
    "            # Sheet 4: Recommendations\n",
    "            if recommendations_df is not None:\n",
    "                recommendations_df.toPandas().to_excel(writer, sheet_name='Recommendations', index=False)\n",
    "            \n",
    "            # Sheet 5: Summary Statistics\n",
    "            summary_data = {\n",
    "                'Metric': [\n",
    "                    'Total Jobs',\n",
    "                    'Total Runs Analyzed',\n",
    "                    'Lookback Period (days)',\n",
    "                    'Overall Success Rate (%)',\n",
    "                    'Critical Jobs',\n",
    "                    'Warning Jobs',\n",
    "                    'Slow Jobs',\n",
    "                    'Stale Jobs',\n",
    "                    'Healthy Jobs',\n",
    "                    'Analysis Date'\n",
    "                ],\n",
    "                'Value': [\n",
    "                    jobs_df.count(),\n",
    "                    job_metrics.agg(F.sum('total_runs')).first()[0],\n",
    "                    LOOKBACK_DAYS,\n",
    "                    f\"{overall_success_rate:.1f}\",\n",
    "                    critical_count if 'critical_count' in dir() else 0,\n",
    "                    warning_count if 'warning_count' in dir() else 0,\n",
    "                    slow_count if 'slow_count' in dir() else 0,\n",
    "                    stale_count if 'stale_count' in dir() else 0,\n",
    "                    job_metrics.filter(F.col('health_category') == 'HEALTHY').count(),\n",
    "                    datetime.now(eastern).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                ]\n",
    "            }\n",
    "            pd.DataFrame(summary_data).to_excel(writer, sheet_name='Summary', index=False)\n",
    "            \n",
    "            # Sheet 6: Execution Statistics\n",
    "            stats_data = {\n",
    "                'Metric': list(execution_stats.keys()),\n",
    "                'Value': list(execution_stats.values())\n",
    "            }\n",
    "            pd.DataFrame(stats_data).to_excel(writer, sheet_name='Execution Stats', index=False)\n",
    "        \n",
    "        # Apply formatting\n",
    "        from openpyxl import load_workbook\n",
    "        from openpyxl.styles import Font, PatternFill, Alignment\n",
    "        \n",
    "        wb = load_workbook(excel_path)\n",
    "        for sheet_name in wb.sheetnames:\n",
    "            ws = wb[sheet_name]\n",
    "            \n",
    "            # Format header row\n",
    "            for cell in ws[1]:\n",
    "                cell.font = Font(bold=True, color='FFFFFF')\n",
    "                cell.fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')\n",
    "                cell.alignment = Alignment(horizontal='center')\n",
    "            \n",
    "            # Auto-adjust column widths\n",
    "            for column in ws.columns:\n",
    "                max_length = 0\n",
    "                column_letter = column[0].column_letter\n",
    "                for cell in column:\n",
    "                    if cell.value:\n",
    "                        max_length = max(max_length, len(str(cell.value)))\n",
    "                ws.column_dimensions[column_letter].width = min(max_length + 2, 50)\n",
    "        \n",
    "        wb.save(excel_path)\n",
    "        \n",
    "        log(f\"✓ Excel workbook created: {excel_path}\")\n",
    "        log(f\"  Sheets: {len(wb.sheetnames)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        log(f\"✗ Excel export failed: {str(e)}\")\n",
    "else:\n",
    "    if not ENABLE_EXCEL_EXPORT:\n",
    "        log(\"ℹ️  Excel export disabled (ENABLE_EXCEL_EXPORT=False)\")\n",
    "    else:\n",
    "        log(\"ℹ️  Excel export skipped (no data)\")\n",
    "\n",
    "log_execution_time(\"Excel Export\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b15f26b1-ac50-44a9-998b-39ddb8a724c2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Export to Delta table"
    }
   },
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "if ENABLE_DELTA_EXPORT and job_metrics is not None:\n",
    "    log(\"\\n\" + \"=\"*60)\n",
    "    log(\"EXPORTING TO DELTA TABLE\")\n",
    "    log(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Add audit metadata\n",
    "        job_metrics_export = job_metrics.withColumn('audit_timestamp', F.current_timestamp())\n",
    "        job_metrics_export = job_metrics_export.withColumn('lookback_days', F.lit(LOOKBACK_DAYS))\n",
    "        job_metrics_export = job_metrics_export.withColumn('execution_time_seconds', F.lit(time.time() - execution_stats['start_time']))\n",
    "        \n",
    "        # Write to Delta table (append mode for historical tracking)\n",
    "        job_metrics_export.write \\\n",
    "            .format('delta') \\\n",
    "            .mode('append') \\\n",
    "            .option('mergeSchema', 'true') \\\n",
    "            .saveAsTable(DELTA_TABLE_NAME)\n",
    "        \n",
    "        log(f\"✓ Delta table updated: {DELTA_TABLE_NAME}\")\n",
    "        log(f\"  Mode: append (historical retention)\")\n",
    "        log(f\"  Rows added: {job_metrics.count()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        log(f\"✗ Delta export failed: {str(e)}\")\n",
    "else:\n",
    "    if not ENABLE_DELTA_EXPORT:\n",
    "        log(\"ℹ️  Delta export disabled (ENABLE_DELTA_EXPORT=False)\")\n",
    "    else:\n",
    "        log(\"ℹ️  Delta export skipped (no data)\")\n",
    "\n",
    "log_execution_time(\"Delta Export\", cell_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f176e6b-e7c6-41c3-922e-c6822f782513",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Execution summary"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXECUTION SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "execution_time = time.time() - execution_stats['start_time']\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"EXECUTION SUMMARY\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "log(f\"\\n⏱️  Total execution time: {execution_time:.2f} seconds\")\n",
    "log(f\"\\n\uD83D\uDCCA Statistics:\")\n",
    "log(f\"  Jobs analyzed: {execution_stats['jobs_processed']}\")\n",
    "log(f\"  Runs analyzed: {execution_stats['runs_processed']}\")\n",
    "log(f\"  API calls: {execution_stats['api_calls']}\")\n",
    "log(f\"  API failures: {execution_stats['api_failures']}\")\n",
    "log(f\"  API retries: {execution_stats['api_retries']}\")\n",
    "\n",
    "if execution_stats['api_calls'] > 0:\n",
    "    success_rate = ((execution_stats['api_calls'] - execution_stats['api_failures']) / execution_stats['api_calls']) * 100\n",
    "    log(f\"  API success rate: {success_rate:.1f}%\")\n",
    "\n",
    "if job_metrics is not None:\n",
    "    log(f\"\\n\uD83C\uDFE5 Job Health Summary:\")\n",
    "    log(f\"  Healthy jobs: {job_metrics.filter(F.col('health_category') == 'HEALTHY').count()}\")\n",
    "    log(f\"  Fair jobs: {job_metrics.filter(F.col('health_category') == 'FAIR').count()}\")\n",
    "    log(f\"  Poor jobs: {job_metrics.filter(F.col('health_category') == 'POOR').count()}\")\n",
    "    log(f\"  Critical jobs: {job_metrics.filter(F.col('health_category') == 'CRITICAL').count()}\")\n",
    "    \n",
    "    avg_health = job_metrics.agg(F.avg('health_score')).first()[0]\n",
    "    log(f\"\\n  Average health score: {avg_health:.1f}/100\")\n",
    "\n",
    "if recommendations_df is not None:\n",
    "    log(f\"\\n\uD83D\uDCA1 Recommendations: {recommendations_df.count()}\")\n",
    "\n",
    "log(\"\\n\" + \"=\"*60)\n",
    "log(\"✓ JOB & WORKFLOW HEALTH ANALYSIS COMPLETE\")\n",
    "log(\"=\"*60)\n",
    "\n",
    "# Return JSON summary for job mode\n",
    "if is_job_mode:\n",
    "    import json\n",
    "    summary = {\n",
    "        'status': 'success',\n",
    "        'execution_time_seconds': execution_time,\n",
    "        'jobs_analyzed': execution_stats['jobs_processed'],\n",
    "        'runs_analyzed': execution_stats['runs_processed'],\n",
    "        'problem_jobs': problem_jobs.count() if problem_jobs is not None else 0,\n",
    "        'recommendations': recommendations_df.count() if recommendations_df is not None else 0,\n",
    "        'timestamp': datetime.now(eastern).isoformat()\n",
    "    }\n",
    "    dbutils.notebook.exit(json.dumps(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3086c742-03ae-400c-aa9a-6024494e0788",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Job & Workflow Health Monitor",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}